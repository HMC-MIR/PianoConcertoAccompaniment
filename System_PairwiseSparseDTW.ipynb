{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# Pairwise Sparse DTW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook implements a pairwise sparse DTW system.  The only requirement in this notebook is that it implement the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`.  The rest of the notebook is for experimenting, visualizing, and analyzing the system, so it should be thought of as a sandbox for development."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ff6b5de",
   "metadata": {},
   "source": [
    "Here is a summary of the pairwise sparse DTW approach:\n",
    "- Offline processing: A subset of features from the orchestra recording is selected based on chroma flux.  This subset of features is then aligned against the full mix recording using a variant of subsequence DTW that appropriately handles the gaps between selected features.\n",
    "- Online processing: The solo piano and full mix recordings are aligned with standard DTW using chroma features, and the predicted alignment is then used to infer the corresponding alignment between the piano and orchestra recordings.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610e1142",
   "metadata": {},
   "source": [
    "In the offline processing stage, three things are computed and stored in the `cache/` folder:\n",
    "- chroma features for the orchestra recording (O features)\n",
    "- chroma features for the full mix recording (PO features)\n",
    "- predicted DTW alignment between the orchestra and full mix recordings using the sparse DTW alignment method.  This approach first selects a subset of the O features that have the highest flux, and then aligns these selected features against the PO features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "import os.path\n",
    "import import_ipynb\n",
    "import align_tools\n",
    "import system_utils\n",
    "from hmc_mir.align import dtw\n",
    "from numba import jit, njit, prange\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length, frac_keep):\n",
    "    '''\n",
    "    Carries out offline processing for the pairwise sparse DTW system.\n",
    "    \n",
    "    Inputs:\n",
    "        scenario_dir: The scenario directory to process\n",
    "        cache_dir: The location of the cache directory\n",
    "        hop_length: The hop length in samples used when computing chroma features\n",
    "        frac_keep: the fraction of orchestra features to use during alignment, scalar between 0 and 1\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    \n",
    "    # setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    if os.path.exists(cache_dir):\n",
    "        # print(f'{cache_dir} has already been processed.  Skipping.')\n",
    "        pass\n",
    "    else:\n",
    "        # setup\n",
    "        os.makedirs(cache_dir)\n",
    "\n",
    "        # compute orchestra features\n",
    "        o_file = f'{scenario_dir}/o.wav'\n",
    "        y_o, sr = lb.core.load(o_file)\n",
    "        F_o = lb.feature.chroma_cqt(y=y_o, sr=sr, hop_length=hop_length, norm=None) \n",
    "\n",
    "        # compute full mix features\n",
    "        po_file = f'{scenario_dir}/po.wav'\n",
    "        y_po, sr = lb.core.load(po_file)\n",
    "        F_po = lb.feature.chroma_cqt(y=y_po, sr=sr, hop_length=hop_length, norm=None)\n",
    "        \n",
    "        # select subset of O features\n",
    "        t_start = time.time()\n",
    "        orch_start_sec, orch_end_sec = system_utils.get_orchestra_start_end_times(scenario_dir)\n",
    "        orch_start_frm = int(np.round(orch_start_sec * sr / hop_length))\n",
    "        orch_end_frm = int(np.round(orch_end_sec * sr / hop_length)) + 1\n",
    "        o_feats_sel, idx_sel, gaplens, flux_thresh = selectFeatures(F_o[:,orch_start_frm:orch_end_frm], frac_keep)\n",
    "                \n",
    "        # compute sparse DTW alignment (orchestra as query) \n",
    "        C = 1 - lb.util.normalize(o_feats_sel, norm=2, axis=0).T @ lb.util.normalize(F_po, norm=2, axis=0)\n",
    "        D, B, wp = dtw_sparse_subseq(C, gaplens)\n",
    "        wp[0,:] = idx_sel[wp[0,:]] # convert back to O frames\n",
    "        wp[0,:] = wp[0,:] + orch_start_frm # account for offset\n",
    "        t_end = time.time()\n",
    "        \n",
    "        # save to cache\n",
    "        np.save(f'{cache_dir}/o_chroma.npy', F_o)\n",
    "        np.save(f'{cache_dir}/po_chroma.npy', F_po)\n",
    "        np.save(f'{cache_dir}/o_po_align.npy', wp)\n",
    "        np.save(f'{cache_dir}/runtime_o_po.npy', t_end - t_start)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b81aca-e12e-4549-9231-b909051a05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(F, frac_keep):\n",
    "    '''\n",
    "    Selects a subset of features that have the highest flux.\n",
    "\n",
    "    Inputs:\n",
    "        F: feature matrix of size DxN, where D is the feature dimension and N is the number of features\n",
    "        frac_keep: the fraction of features to keep, a scalar between 0 and 1\n",
    "\n",
    "    Returns:\n",
    "        F_sel: a DxM feature matrix containing the selected subset of features\n",
    "        idx_sel: an array of length M specifying the indices of the features that were selected\n",
    "        gaplens: an array of length M specifying the gap lengths between selected features\n",
    "        flux_thresh: the threshold used to select features based on their flux\n",
    "    '''\n",
    "    flux_vals = np.sum(np.abs(F[:,0:-1] - F[:,1:]), axis=0)\n",
    "    flux_thresh = sorted(flux_vals, reverse=True)[int(np.round(frac_keep * len(flux_vals)))-1]\n",
    "    idx_sel = np.where(np.array(flux_vals > flux_thresh) == 1)[0]\n",
    "    gaplens = idx_sel[1:] - idx_sel[0:-1]\n",
    "    gaplens = np.append(gaplens, len(flux_vals) - idx_sel[-1])\n",
    "    F_sel = F[:,idx_sel]\n",
    "    \n",
    "    return F_sel, idx_sel, gaplens, flux_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cd131-7bfe-47c6-b443-369251ec2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def dtw_sparse_subseq(C, gaplens):\n",
    "    '''\n",
    "    A variant of subsequence DTW that aligns a selected subset of query features against a longer reference sequence.\n",
    "    The query sequence can start and end anywhere in the reference sequence, and the alignment handles gaps between\n",
    "    selected query features.\n",
    "    \n",
    "    Inputs:\n",
    "        C: an MxN matrix of pairwise costs, where M is the length of the (selected) query features and N is the length of\n",
    "           the reference sequence\n",
    "        gaplens: an array of length M specifying the gap lengths between selected features\n",
    "\n",
    "    Returns:\n",
    "        D: cumulative cost matrix, size MxN\n",
    "        B: backtrace matrix of size MxN, each element specifies either the step index (if dense matching)\n",
    "           or the number of reference frames skipped (if sparse matching)\n",
    "        path: a numpy array of (row, col) coordinates for the optimal path\n",
    "    '''\n",
    "    D = np.ones(C.shape) * np.inf\n",
    "    B = np.zeros(C.shape, dtype=np.int32)\n",
    "    steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "    weights = np.array([1,1,2])\n",
    "\n",
    "    D[0, :] = C[0,:]\n",
    "\n",
    "    for row in range(1, C.shape[0]):\n",
    "        for col in range(1, C.shape[1]):\n",
    "            \n",
    "            if row >= 2 and gaplens[row-2] == 1 and gaplens[row-1] == 1:\n",
    "                \n",
    "                # dense matching\n",
    "                bestCost = D[row, col]\n",
    "                bestCostIndex = -1\n",
    "                for stepIndex in range(steps.shape[0]):\n",
    "                    if row - steps[stepIndex][0] >= 0 and col - steps[stepIndex][1] >= 0:\n",
    "                        costForStep = C[row, col] * weights[stepIndex] + D[row - steps[stepIndex][0], col - steps[stepIndex][1]]\n",
    "                        if costForStep < bestCost:\n",
    "                            bestCost = costForStep\n",
    "                            bestCostIndex = stepIndex\n",
    "                D[row, col] = bestCost\n",
    "                B[row, col] = bestCostIndex\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # sparse matching\n",
    "                cstep_lbound = int(np.ceil(gaplens[row-1]/2))\n",
    "                cstep_ubound = gaplens[row-1]*2 + 1\n",
    "                bestCost = D[row, col]\n",
    "                for cstep in range(cstep_lbound, cstep_ubound):\n",
    "                    rprev = row - 1\n",
    "                    cprev = col - cstep\n",
    "                    if cprev >= 0:\n",
    "                        costForStep = C[row, col] + D[rprev, cprev]\n",
    "                        if costForStep < bestCost:\n",
    "                            bestCost = costForStep\n",
    "                            bestCostIndex = cstep\n",
    "                D[row, col] = bestCost\n",
    "                B[row, col] = bestCostIndex\n",
    "                \n",
    "    path = dtw_backtrace_sparse(D, B, gaplens, steps, subseq=True)\n",
    "    path.reverse()\n",
    "    path = np.array(path).T\n",
    "\n",
    "    return D, B, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0916d-0bb0-4552-9da9-2aae53310533",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def dtw_backtrace_sparse(D, B, gaplens, steps, subseq):\n",
    "    '''\n",
    "    Backtraces through the cumulative cost matrix D\n",
    "    \n",
    "    Inputs:\n",
    "        D: cumulative cost matrix\n",
    "        B: backtrace matrix\n",
    "        gaplens: array specifying the gap lengths between selected features\n",
    "        steps: a numpy matrix specifying the allowable transitions.  It should be of dimension (L, 2), where each row specifies (row step, col step)\n",
    "        subseq: boolean indicating whether to assume a subsequence alignment\n",
    "    \n",
    "    Returns:\n",
    "        A numpy array of (row, col) coordinates for the optimal path.\n",
    "    '''\n",
    "\n",
    "    rstart = B.shape[0] - 1\n",
    "    if subseq:\n",
    "        cstart = np.argmin(D[-1])\n",
    "    else:\n",
    "        cstart = B.shape[1] - 1\n",
    "    pos = (rstart, cstart)\n",
    "    path = []\n",
    "    path.append(pos)\n",
    "    while (pos[0] != 0 and pos[1] != 0) or (pos[0] and subseq):\n",
    "        \n",
    "        (row, col) = pos\n",
    "        if row >= 2 and gaplens[row-1] == 1 and gaplens[row-2] == 1:\n",
    "            \n",
    "            # dense matching\n",
    "            stepidx = B[row, col]\n",
    "            (rstep, cstep) = steps[stepidx]\n",
    "            pos = (row-rstep, col-cstep)\n",
    "            path.append(pos)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # sparse matching\n",
    "            rstep = 1\n",
    "            cstep = B[row, col]\n",
    "            pos = (row-rstep, col-cstep)\n",
    "            path.append(pos)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/o_chroma.npy'), f'o_chroma.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/po_chroma.npy'), f'po_chroma.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/o_po_align.npy'), f'o_po_align.npy missing from {indir}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "# Online Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cedd6f21",
   "metadata": {},
   "source": [
    "In the online processing stage, we do two things:\n",
    "- estimate the P-PO alignment using standard subsequence DTW with chroma features, and\n",
    "- infer the P-O alignment based on the estimated P-PO and O-PO alignments\n",
    "\n",
    "Note that this baseline system is not a valid online system since it uses offline DTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3344e9-0a19-4188-ac2c-cf20c6b05720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(scenario_dir, out_dir, cache_dir, hop_length, steps, weights):\n",
    "    '''\n",
    "    Carries out `online' processing for the pairwise sparse DTW system.\n",
    "    \n",
    "    Inputs:\n",
    "        scenario_dir: The scenario directory to process\n",
    "        out_dir: The directory to put results, intermediate files, and logging info\n",
    "        cache_dir: The cache directory\n",
    "        hop_length: The hop length in samples used when computing chroma features\n",
    "        steps: an L x 2 array specifying the allowable DTW transitions\n",
    "        weights: a length L array specifying the DTW transition weights\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    \n",
    "    # verify & setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "    # compute features\n",
    "    p_file = f'{scenario_dir}/p.wav'\n",
    "    y, sr = lb.core.load(p_file)\n",
    "    F_p = lb.feature.chroma_cqt(y=y, sr=sr, hop_length=hop_length, norm=2)  # piano features\n",
    "    F_po = np.load(f'{cache_dir}/po_chroma.npy') # full mix features\n",
    "        \n",
    "    # precomputed PO-O alignment\n",
    "    hop_sec = hop_length / sr\n",
    "    wp_BC = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "    wp_BC = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC)) # prepend (0,0) to handle edge cases properly\n",
    "   \n",
    "    # compute P-PO alignment\n",
    "    t_start = time.time()\n",
    "    C = align_tools.cosine_dist(F_p, F_po)\n",
    "    _, _, wp_AB = dtw.dtw(C, steps, weights, True)\n",
    "    t_end = time.time()\n",
    "\n",
    "    # infer piano-orchestra alignment\n",
    "    wp_AC = align_tools.infer_alignment(wp_AB, wp_BC, frames=True)\n",
    "    np.save(f'{out_dir}/hyp.npy', wp_AC*hop_sec)\n",
    "    np.save(f'{out_dir}/runtime_p_po.npy', t_end - t_start)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19710221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "\n",
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s2'\n",
    "# out_dir = 'experiments/test/s2'\n",
    "# cache_dir = 'experiments/test/cache'\n",
    "# hop_size = 512\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3])\n",
    "# offline_processing(scenario_dir, cache_dir, hop_size, steps, weights)\n",
    "# online_processing(scenario_dir, out_dir, cache_dir, hop_size, steps, weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PianoConcertoAccompaniment",
   "language": "python",
   "name": "pianoconcertoaccompaniment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
