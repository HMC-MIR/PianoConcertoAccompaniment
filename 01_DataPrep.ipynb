{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we download and prepare the audio data for running automated concerto accompaniment experiments.\n",
    "\n",
    "There are five sections below, which set up and/or explain the content in five different folders in the root directory: `cfg_files/`, `audio/`, `annot/`, `queries/`, and `scenarios/`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary configuration files are in the `cfg_files/` directory.  There are three files:\n",
    "- `train.list`: specifies a list of the concerto movements that will be used for training\n",
    "- `test.list`: specifies a list of the concerto movements that will be used for testing\n",
    "- `AudioDataSummary.csv`: contains information about each audio recording, including urls and licenses.\n",
    "\n",
    "Because we are planning to expand the dataset, for now we place all movements in `train.list` and leave `test.list` empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LIST_FILE = 'cfg_files/train.list'\n",
    "AUDIO_SUMMARY_FILE = 'cfg_files/AudioDataSummary.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section sets up the `audio/` folder.  There are three types of audio files in this benchmark:\n",
    "- Full mix recordings.  The full mix recordings are downloaded from IMSLP by running the bash script download_fullmixes.sh below.\n",
    "- Piano only recordings.  A set of piano only recordings were collected for this project and can be downloaded through a link provided below.\n",
    "- Orchestra only recordings.  The orchestra only recordings are taken from Music Minus One and are under a private license.  They must be purchased, downloaded, and renamed as described below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All audio recordings will be stored in the `audio/` directory with the naming convention `<piece>_<movement>_<id>.<extension>`.  The `<id>` contains one of the following tags:\n",
    "- 'PO': piano + orchestra\n",
    "- 'P': piano only\n",
    "- 'O': orchestra only\n",
    "\n",
    "as well as a number identifier.  For example, `rach2_mov1_PO2.mp3` is a full mix recording of the first movement in Rachmaninov's Piano Concerto No. 2.\n",
    "\n",
    "See `cfg_files/AudioDataSummary.csv` for more detailed information about each recording, including urls and licenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from system_utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import system_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_ROOT = 'audio'\n",
    "if not os.path.exists(AUDIO_ROOT):\n",
    "    os.mkdir(AUDIO_ROOT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following bash script to download the full mixes from IMSLP.  These will be saved under the Audio/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘audio/rach2_mov1_PO1.mp3’ already there; not retrieving.\n",
      "File ‘audio/rach2_mov1_PO2.mp3’ already there; not retrieving.\n",
      "File ‘audio/mozart21_mov1_PO1.mp3’ already there; not retrieving.\n",
      "File ‘audio/mozart21_mov1_PO2.mp3’ already there; not retrieving.\n",
      "File ‘audio/beeth1_mov1_PO1.mp3’ already there; not retrieving.\n",
      "File ‘audio/beeth1_mov1_PO2.mp3’ already there; not retrieving.\n",
      "File ‘audio/beeth1_mov1_PO3.mp3’ already there; not retrieving.\n",
      "File ‘audio/beeth1_mov1_PO4.mp3’ already there; not retrieving.\n",
      "File ‘audio/beeth1_mov1_PO5.mp3’ already there; not retrieving.\n",
      "File ‘audio/bach5_mov1_PO1.mp3’ already there; not retrieving.\n",
      "File ‘audio/bach5_mov1_PO2.mp3’ already there; not retrieving.\n",
      "File ‘audio/rach2_mov2_PO1.mp3’ already there; not retrieving.\n",
      "File ‘audio/rach2_mov2_PO2.mp3’ already there; not retrieving.\n",
      "File ‘audio/rach2_mov3_PO1.mp3’ already there; not retrieving.\n",
      "File ‘audio/rach2_mov3_PO2.mp3’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!bash download_fullmixes.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the following [zip file containing the piano only recordings](https://drive.google.com/file/d/1daMHu-jq2WZ7nN99dPFlsZd8qc4KOeVd/view?usp=sharing) and place the audio recordings in the `audio/` directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orchestra only recordings are taken from the [Music Minus One Library](https://www.halleonard.com/series/MMONE?dt=item#products).  These are under a private license and must be purchased directly from the Hal Leonard website.  Once downloaded, the orchestra only files should be put in the `audio/` folder and renamed as described below.\n",
    "- [Rachmaninov Piano Concerto No. 2 Mov. 1](https://www.halleonard.com/product-family/PC25985/rachmaninov-concerto-no-2-in-c-minor-op-18): rach2_mov1_O1.wav\n",
    "- [Mozart Piano Concerto No. 21 Mov. 1](https://www.halleonard.com/product/400239/mozart-concerto-no-21-in-c-major-kv467-elvira-madigan): mozart21_mov1_O1.wav\n",
    "- [Beethoven Piano Concerto No. 1 Mov. 1](https://www.halleonard.com/product-family/PC25983/beethoven-concerto-no-1-in-c-major-op-15): beeth1_mov1_O1.wav\n",
    "- [Bach Harpsichord Concerto No. 5 Mov. 1](https://www.halleonard.com/product/44006419/bach-concerto-for-piano-strings-and-basso-continuo-bwv-1056-in-f-minor): bach5_mov1_O1.wav\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total cost of purchasing the MMO recordings in this dataset is approximately 96 USD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to verify that all of the required audio files are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_audio_dataset():\n",
    "    '''\n",
    "    Verifies that all of the required audio files for running experiments are present.\n",
    "    '''\n",
    "    passed = True\n",
    "    d = pd.read_csv(AUDIO_SUMMARY_FILE)\n",
    "    \n",
    "    for filename in d['id']:\n",
    "        filepath = f'{AUDIO_ROOT}/{filename}'\n",
    "        if not os.path.exists(filepath):\n",
    "            passed = False\n",
    "            print(f'Missing file: {filepath}')\n",
    "    \n",
    "    if passed:\n",
    "        print('All required files are present.')\n",
    "    else:\n",
    "        print('Missing files should be placed in audio/ before moving on.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required files are present.\n"
     ]
    }
   ],
   "source": [
    "verify_audio_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert all mp3 files to wav.  From this point forward, we will work exclusively with wav files.  The code below requires that ffmpeg be installed and available on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav():\n",
    "    '''\n",
    "    Converts all the mp3 files to wav files with the same basename.  If timestamps are specified,\n",
    "    trim the recording to only include the specified time interval.\n",
    "    '''    \n",
    "    d = system_utils.get_audio_summary_info()\n",
    "    for audiofile in d:\n",
    "        basename, ext = os.path.splitext(audiofile)\n",
    "        if ext == '.mp3':\n",
    "            src_filepath = f'{AUDIO_ROOT}/{basename}.mp3'\n",
    "            dst_filepath = f'{AUDIO_ROOT}/{basename}.wav'\n",
    "            if not os.path.exists(dst_filepath):\n",
    "                if d[audiofile] is not None: \n",
    "                    (tStart, tEnd) = d[audiofile] # extract specified time interval\n",
    "                    print(f'Converting {src_filepath} to .wav ({tStart}, {tEnd})')\n",
    "                    os.system(f'ffmpeg -i {src_filepath} -ar 44100 -ss {tStart} -to {tEnd} {dst_filepath}')\n",
    "                else:\n",
    "                    print(f'Converting {src_filepath} to .wav') \n",
    "                    os.system(f'ffmpeg -i {src_filepath} -ar 44100 {dst_filepath}') # convert whole recording\n",
    "            else:\n",
    "                print(f'File {src_filepath} has already been converted to wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File audio/rach2_mov1_PO1.mp3 has already been converted to wav\n",
      "File audio/rach2_mov1_PO2.mp3 has already been converted to wav\n",
      "File audio/mozart21_mov1_PO1.mp3 has already been converted to wav\n",
      "File audio/mozart21_mov1_PO2.mp3 has already been converted to wav\n",
      "File audio/beeth1_mov1_PO1.mp3 has already been converted to wav\n",
      "File audio/beeth1_mov1_PO2.mp3 has already been converted to wav\n",
      "File audio/bach5_mov1_PO1.mp3 has already been converted to wav\n",
      "File audio/bach5_mov1_PO2.mp3 has already been converted to wav\n"
     ]
    }
   ],
   "source": [
    "convert_mp3_to_wav()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annotation files are already included in the `annot/` directory.  There are three kinds of files:\n",
    "- `.beats`: These are files specifying the timestamps of measure downbeats.  There is one `.beats` file for each piano (only) and orchestra (only) recording.  Note that the orchestra only and piano only recordings are synchronized by design, so the piano annotation file is simply a soft link to the orchestra annotation file.  The full mix recordings do not have timestamp annotations, since they are only used as auxiliary information.\n",
    "- `query.measures`: Each concerto movement is broken into a series of chunks corresponding to music segments in which the pianist is playing continuously.  This file indicates the measure numbers of each music segment.  Each music segment will serve as a query in our benchmark.\n",
    "- `eval.measures`: We can only evaluate alignment quality in sections where both orchestra and piano are active.  This file indicates which measures in the concerto movement will be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOT_ROOT = 'annot'\n",
    "QUERY_MEASURES_FILE = f'{ANNOT_ROOT}/query.measures'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script sets up the soft links for piano annotation files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'annot/bach5_mov1_P1.beats': File exists\n",
      "ln: failed to create symbolic link 'annot/beeth1_mov1_P1.beats': File exists\n",
      "ln: failed to create symbolic link 'annot/mozart21_mov1_P1.beats': File exists\n",
      "ln: failed to create symbolic link 'annot/rach2_mov1_P1.beats': File exists\n"
     ]
    }
   ],
   "source": [
    "!bash setup_annot_links.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The audio queries will be generated and stored in the `queries/` directory.  As described above, each query is a single contiguous chunk of solo piano playing (as defined by the `query.measures` file).  Because we have a limited amount of data, we will augment the dataset by considering time scale modified versions of the original piano only recordings.  Each time scale modified version will need its own appropriately modified beat annotation file, which are generated and included in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "from hmc_mir import tsm_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files(regexp):\n",
    "    '''\n",
    "    Returns a list of audio filenames matching a given regular expression.\n",
    "    \n",
    "    Inputs\n",
    "    regexp: a string specifying the regular expression\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(AUDIO_SUMMARY_FILE)\n",
    "    p_list = [a for a in df['id'] if re.search(regexp, a)] \n",
    "    return p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tsm_audio(infile, outfile, tsm_factor):\n",
    "    '''\n",
    "    Applies time-scale modification to a given audio recording and saves the generated audio to file.\n",
    "    \n",
    "    Inputs\n",
    "    infile: The filepath of the input audio\n",
    "    outfile: The filepath of the output audio\n",
    "    tsm_factor: The time-scale modification factor to apply\n",
    "    '''\n",
    "    if tsm_factor == 1: # just copy the file\n",
    "        shutil.copyfile(infile, outfile)\n",
    "    else:\n",
    "        y, sr = lb.load(infile)\n",
    "        y_mod = tsm_tools.tsm_hybrid(y, tsm_factor, sr)\n",
    "        sf.write(outfile, y_mod, sr, subtype = 'PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_annots_tsm(infile, outfile, tsm_factor):\n",
    "    '''\n",
    "    Modifies an annotation file according to a single global time-scale modification factor.\n",
    "    \n",
    "    Inputs\n",
    "    infile: the annotation file to be modified\n",
    "    tsm_factor: the time-scale modification factor to apply\n",
    "    outfile: the output annotation file\n",
    "    '''\n",
    "    df = pd.read_csv(infile)\n",
    "    df['start'] = df['start'] * tsm_factor\n",
    "    df.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_timestamps(piece_id, query_measures_file, annot_file):\n",
    "    '''\n",
    "    This function infers the timestamp locations of all queries in a piano only recording.\n",
    "    \n",
    "    Inputs\n",
    "    piece_id: A string specifying the piece and movement, e.g. 'rach2_mov1'\n",
    "    query_measures_file: Filepath to the query.measures file that specifies the measures in each query\n",
    "    annot_file: Filepath to the annotation file that specifies timestamps for measure downbeats\n",
    "    \n",
    "    Returns a list of (tstart,tend) tuples that indicate the starting and ending timestamps \n",
    "    of each query in the piano only recording.\n",
    "    '''\n",
    "\n",
    "    # read annotation file\n",
    "    df = pd.read_csv(annot_file) # has two columns: start (timestamp) and measure (number)\n",
    "    \n",
    "    # get query measure info\n",
    "    d = {}\n",
    "    with open(query_measures_file,'r') as f:\n",
    "        for line in f: \n",
    "            parts = line.split(',') # e.g. 'rach2_mov1,1-75,83-161,177-297,313-374'\n",
    "            cur_piece = parts[0]\n",
    "            parts.pop(0)\n",
    "            d[cur_piece] = parts\n",
    "    if piece_id not in d:\n",
    "        raise Exception(f\"Cannot find entry for {piece_id} in {query_measures_file}.  Aborting.\")\n",
    "        \n",
    "    # infer timestamps        \n",
    "    times = []\n",
    "    measures = []\n",
    "    for pair in d[piece_id]:\n",
    "        parts = pair.split('-')\n",
    "        assert len(parts) == 2\n",
    "        start_measure, end_measure = parts\n",
    "        start_time = float(df.loc[df['measure'] == int(start_measure), 'start'])\n",
    "        end_time = float(df.loc[df['measure'] == int(end_measure), 'start'])\n",
    "        measures.append((int(start_measure), int(end_measure)))\n",
    "        times.append((start_time, end_time))\n",
    "                    \n",
    "    return measures, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_excerpt(infile, outfile, starttime, endtime):\n",
    "    '''\n",
    "    Extracts an audio segment from a given audio recording and writes the output to file.\n",
    "    \n",
    "    Inputs\n",
    "    infile: The input audio recording from which the excerpt should be taken\n",
    "    outfile: The output audio file to write\n",
    "    starttime: The start time in seconds of the selected segment\n",
    "    endtime: The end time in seconds of the selected segment\n",
    "    '''\n",
    "    y, sr = lb.load(infile)\n",
    "    start_sample = int(np.round(starttime * sr))\n",
    "    end_sample = int(np.around(endtime * sr))\n",
    "    assert end_sample < len(y)\n",
    "    sf.write(outfile, y[start_sample:end_sample], sr, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_annots_select(infile, outfile, select_start, select_end):\n",
    "    '''\n",
    "    Modifies an annotation file by selecting a specified interval in the recording.\n",
    "    Only annotations that fall within the interval will be included in the modified \n",
    "    annotation file, and the timestamps will be expressed relative to the interval start time.\n",
    "    \n",
    "    Inputs\n",
    "    infile: the annotation file to be modified\n",
    "    outfile: the output annotation file\n",
    "    select_start: the start of the selected interval (in sec)\n",
    "    select_end: the end of the selected interval (in sec)\n",
    "    '''\n",
    "    df = pd.read_csv(infile)\n",
    "    select_rows = (df['start'] >= select_start) & (df['start'] <= select_end)\n",
    "    df.loc[:,'start'] = df['start'] - select_start\n",
    "    df = df[select_rows]\n",
    "    df.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQueries(outdir, tsm_factors):\n",
    "    '''\n",
    "    Preps and generates time-scale modified audio queries and annotation files.\n",
    "    \n",
    "    Inputs\n",
    "    outdir: directory to create and populate with audio queries\n",
    "    tsm_factors: list of time-scale modification factors to use in generating queries\n",
    "    '''\n",
    "    \n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)    \n",
    "    \n",
    "    for p_file in get_audio_files(r'_P\\d+.\\S+$'): # all solo piano \n",
    "        \n",
    "        base_id = os.path.splitext(p_file)[0] # e.g. rach2_mov1_P1\n",
    "        piece_dir = f'{outdir}/{base_id}'\n",
    "        \n",
    "        if os.path.exists(piece_dir):\n",
    "            print(f'Directory {piece_dir} already exists.  Skipping.')\n",
    "            continue\n",
    "        os.mkdir(piece_dir)\n",
    "        \n",
    "        for tsm_factor in tsm_factors:\n",
    "            \n",
    "            tsm_dir = f'{piece_dir}/tsm{tsm_factor:.2f}' # e.g. outdir/rach2_mov1_P1/tsm0.85\n",
    "            os.mkdir(tsm_dir)\n",
    "            \n",
    "            # generate time-scale modified audio\n",
    "            tsm_id = f'{base_id}_tsm{tsm_factor:.2f}_all' # e.g. rach2_mov1_P1_tsm0.85_all\n",
    "            orig_audio_file = f'{AUDIO_ROOT}/{p_file}'\n",
    "            tsm_audio_file = f'{tsm_dir}/{tsm_id}.wav'\n",
    "            generate_tsm_audio(orig_audio_file, tsm_audio_file, tsm_factor)\n",
    "            \n",
    "            # generate time-scale modified annotation file\n",
    "            orig_annot_file = f'{ANNOT_ROOT}/{base_id}.beats'\n",
    "            tsm_annot_file = f'{tsm_dir}/{tsm_id}.beats'\n",
    "            modify_annots_tsm(orig_annot_file, tsm_annot_file, tsm_factor)\n",
    "            \n",
    "            # get query start & end timestamps\n",
    "            piece_id = re.sub(r'_P1$','', base_id) # e.g. rach2_mov1\n",
    "            _, query_tuples = get_query_timestamps(piece_id, QUERY_MEASURES_FILE, tsm_annot_file)\n",
    "            \n",
    "            for cnt, (query_start, query_end) in enumerate(query_tuples):\n",
    "                \n",
    "                # generate query audio file\n",
    "                query_id = f'{base_id}_tsm{tsm_factor:.2f}_q{cnt+1}' # e.g. rach2_mov1_P1_tsm0.85_q1\n",
    "                query_audio_file = f'{tsm_dir}/{query_id}.wav'\n",
    "                extract_audio_excerpt(tsm_audio_file, query_audio_file, query_start, query_end)\n",
    "                \n",
    "                # generate query annotation file\n",
    "                query_annot_file = f'{tsm_dir}/{query_id}.beats'\n",
    "                modify_annots_select(tsm_annot_file, query_annot_file, query_start, query_end)\n",
    "                \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES_ROOT = 'queries'\n",
    "tsm_factors = [0.8, 0.9, 1, 1.11, 1.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateQueries(QUERIES_ROOT, tsm_factors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment Scenarios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark consists of a set of alignment scenarios that are saved in the `scenarios/` directory.  Here, we define a single alignment scenario to be a tuple of three recordings:\n",
    "- Piano query.  This is the user's audio input and should be processed in an online fashion.\n",
    "- Orchestra only recording.  This is the accompaniment that we would like to time scale modify in order to match the user's playing.\n",
    "- Full mix recording.  This recording serves as an intermediary that allows us to align the piano and orchestra recordings.\n",
    "\n",
    "The goal of the alignment scenario is to accurately estimate where we are in the orchestra recording in an online fashion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alignment scenarios are simply numbered sequentially (e.g. `s1/`, `s2/`, etc), and each scenario has its own directory containing the following:\n",
    "- p.wav: This is a soft link to the piano query recording.\n",
    "- o.wav: This is a soft link to the orchestra only recording.\n",
    "- po.wav: This is a soft link to the full mix recording.\n",
    "- p.beats: This is a soft link to the piano query annotation file.\n",
    "- o.beats: This is a soft link to the orchestra annotation file.\n",
    "- scenarios.summary: This contains information about the recordings in the scenario.\n",
    "\n",
    "Each line of the `scenarios.summary` file has the following fields:\n",
    "- scenario id: a identifier for each scenario (e.g. s1, s2, etc)\n",
    "- piano file: a filepath to the piano recording\n",
    "- orchestra file: a filepath to the orchestra recording\n",
    "- full mix file: a filepath to the full mix recording\n",
    "- measure start: the index of the starting measure in the query (counting starts from 1)\n",
    "- measure end: the index of the ending measure in the query (inclusive)\n",
    "- piano start: the timestamp in the original full piano recording where the query begins, specified in seconds\n",
    "- piano end: the timestamp in the original full piano recording where the query ends, specified in seconds\n",
    "- orchestra start: the ground truth timestamp in the orchestra recording corresponding to the beginning of the query, specified in seconds\n",
    "- orchestra end: the ground truth timestamp in the orchestra recording corresponding to the end of the query, specified in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_piece_ids(infile):\n",
    "    '''\n",
    "    Parses the train.list or test.list configuration file and returns a list of piece ids to process.\n",
    "    \n",
    "    Inputs\n",
    "    infile: the filepath to train.list or test.list\n",
    "    \n",
    "    Returns a list of piece ids.\n",
    "    '''\n",
    "    \n",
    "    ids = []\n",
    "    with open(infile,'r') as f:\n",
    "        for line in f:\n",
    "            ids.append(line.strip())\n",
    "    return ids        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myLogger(logfile, loginfo):\n",
    "    '''\n",
    "    Writes logging information to a specified log file.\n",
    "    \n",
    "    Inputs\n",
    "    logfile: name of log file to generate\n",
    "    loginfo: either a string or a list of strings to write to the log file\n",
    "    '''\n",
    "    \n",
    "    assert not os.path.exists(logfile)\n",
    "    with open(logfile, 'w') as f:\n",
    "        if type(loginfo) == list:\n",
    "            for ln in loginfo:\n",
    "                f.write(ln)\n",
    "        else:\n",
    "            f.write(loginfo)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateScenarios(outdir, piece_list, tsm_factors):\n",
    "    '''\n",
    "    Constructs alignment scenarios and populates scenario directories with relevant audio and annotation files.\n",
    "    \n",
    "    Inputs\n",
    "    outdir: the root directory to create and populate with scenario directories\n",
    "    piece_list: filepath of text file containing a list of piece ids to process\n",
    "    tsm_factors: list of time-scale modification factors to consider\n",
    "    '''\n",
    "    \n",
    "    if os.path.exists(outdir):\n",
    "        print(f\"Directory {outdir}/ already exists.  Aborting.\") \n",
    "        return  # very fast to generate, so easiest way is to just delete directory and re-generate from scratch\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "    cnt = 0\n",
    "    logInfo = [] # debug info for logging\n",
    "    \n",
    "    for piece_id in get_piece_ids(piece_list): # e.g. rach2_mov1\n",
    "        \n",
    "        for fullmix_file in get_audio_files(f'^{piece_id}_PO\\d+.\\S+$'): # full mixes, e.g. rach2_mov1_PO2.mp3\n",
    "            fullmix_file = re.sub(r'.mp3$', '.wav', fullmix_file) # use wav file (not mp3)\n",
    "        \n",
    "            for tsm_factor in tsm_factors:\n",
    "                \n",
    "                tsm_id = f'{piece_id}_P1_tsm{tsm_factor:.2f}'\n",
    "                tsm_dir = f'{QUERIES_ROOT}/{piece_id}_P1/tsm{tsm_factor:.2f}'\n",
    "                tsm_annot_file = f'{tsm_dir}/{tsm_id}_all.beats'\n",
    "                o_annot_file = f'{ANNOT_ROOT}/{piece_id}_O1.beats'\n",
    "                assert os.path.exists(tsm_annot_file)\n",
    "                assert os.path.exists(o_annot_file)\n",
    "                measures, q_times = get_query_timestamps(piece_id, QUERY_MEASURES_FILE, tsm_annot_file)\n",
    "                _, o_times = get_query_timestamps(piece_id, QUERY_MEASURES_FILE, o_annot_file)\n",
    "                \n",
    "                for (m, qt, ot, queryIdx) in zip(measures, q_times, o_times, np.arange(len(measures))+1): # queries\n",
    "                    \n",
    "                    cnt += 1\n",
    "                    scenario_dir = f'{outdir}/s{cnt}'\n",
    "                    os.mkdir(scenario_dir)\n",
    "                    cwd = os.getcwd()\n",
    "                    \n",
    "                    # piano only audio (query)\n",
    "                    p_audio = f'{cwd}/{tsm_dir}/{tsm_id}_q{queryIdx}.wav'\n",
    "                    p_link = f'{scenario_dir}/p.wav' # soft links must be absolute paths\n",
    "                    os.symlink(p_audio, p_link)\n",
    "                                        \n",
    "                    # orchestra only audio\n",
    "                    o_audio = f'{cwd}/{AUDIO_ROOT}/{piece_id}_O1.wav'\n",
    "                    o_link = f'{scenario_dir}/o.wav'\n",
    "                    os.symlink(o_audio, o_link)\n",
    "                    \n",
    "                    # full mix audio\n",
    "                    po_audio = f'{cwd}/{AUDIO_ROOT}/{fullmix_file}'\n",
    "                    po_link = f'{scenario_dir}/po.wav'\n",
    "                    os.symlink(po_audio, po_link)\n",
    "                    \n",
    "                    # query annotation\n",
    "                    query_annot = f'{cwd}/{tsm_dir}/{tsm_id}_q{queryIdx}.beats'\n",
    "                    query_annot_link = f'{scenario_dir}/p.beats'\n",
    "                    os.symlink(query_annot, query_annot_link)\n",
    "                    \n",
    "                    # orchestra annotation\n",
    "                    o_annot = f'{cwd}/{ANNOT_ROOT}/{piece_id}_O1.beats'\n",
    "                    o_annot_link = f'{scenario_dir}/o.beats'\n",
    "                    os.symlink(o_annot, o_annot_link)\n",
    "                    \n",
    "                    # log file\n",
    "                    # The format is: s1 p_file o_file po_file meas_start meas_end p_start p_end o_start o_end\n",
    "                    logfile = f'{scenario_dir}/scenario.info'\n",
    "                    logstr = f's{cnt} {p_audio} {o_audio} {po_audio} {m[0]} {m[1]} {qt[0]} {qt[1]} {ot[0]} {ot[1]}\\n'\n",
    "                    myLogger(logfile, logstr)\n",
    "                    logInfo.append(logstr)\n",
    "                    \n",
    "    # summary log file                \n",
    "    myLogger(f'{outdir}/scenarios.summary', logInfo)\n",
    "    \n",
    "    return          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS_ROOT = 'scenarios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateScenarios(SCENARIOS_ROOT, TRAIN_LIST_FILE, tsm_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
