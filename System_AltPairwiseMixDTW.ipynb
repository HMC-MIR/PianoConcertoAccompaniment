{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# Alternating Pairwise Mixture DTW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook implements an Alternating Pairwise Mixture DTW approach.  The only requirement in this notebook is that it implement the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`.\n",
    "\n",
    "Our main findings:\n",
    "- This approach takes much longer to compute (since we have to run several iterations) and does not lead to improved performance (very miniscule improvements)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610e1142",
   "metadata": {},
   "source": [
    "In the offline processing stage, three things are computed and stored in the `cache/` folder:\n",
    "- chroma features for the orchestra recording\n",
    "- chroma features for the full mix recording\n",
    "- predicted DTW alignment between the orchestra and full mix recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "import os.path\n",
    "import import_ipynb\n",
    "import align_tools\n",
    "import system_utils\n",
    "from hmc_mir.align import dtw, isa\n",
    "from numba import jit, njit, prange\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length):\n",
    "    '''\n",
    "    Carries out offline processing for a simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    cache_dir: The location of the cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    \n",
    "    # setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    if os.path.exists(cache_dir):\n",
    "        # print(f'{cache_dir} has already been processed.  Skipping.')\n",
    "        pass\n",
    "    else:\n",
    "        # setup\n",
    "        os.makedirs(cache_dir)\n",
    "\n",
    "        # compute orchestra features\n",
    "        o_file = f'{scenario_dir}/o.wav'\n",
    "        y_o, sr = lb.core.load(o_file)\n",
    "        F_o = lb.feature.chroma_cqt(y=y_o, sr=sr, hop_length=hop_length, norm=None) \n",
    "\n",
    "        # compute full mix features\n",
    "        po_file = f'{scenario_dir}/po.wav'\n",
    "        y_po, sr = lb.core.load(po_file)\n",
    "        F_po = lb.feature.chroma_cqt(y=y_po, sr=sr, hop_length=hop_length, norm=None)\n",
    "      \n",
    "        # compute subsequence DTW alignment (orchestra as query) \n",
    "        orch_start_sec, orch_end_sec = system_utils.get_orchestra_start_end_times(scenario_dir)\n",
    "        orch_start_frm = int(np.round(orch_start_sec * sr / hop_length))\n",
    "        orch_end_frm = int(np.round(orch_end_sec * sr / hop_length)) + 1\n",
    "        C = 1 - lb.util.normalize(F_o[:,orch_start_frm:orch_end_frm], norm=2, axis=0).T @ lb.util.normalize(F_po, norm=2, axis=0)\n",
    "        wp = align_tools.compute_dtw_alignment(C, np.array([[1,1],[1,2],[2,1]]), [1,1,2], subseq = True)        \n",
    "        wp[0,:] = wp[0,:] + orch_start_frm  # account for offset\n",
    "\n",
    "        # save to cache\n",
    "        np.save(f'{cache_dir}/o_chroma.npy', F_o)\n",
    "        np.save(f'{cache_dir}/po_chroma.npy', F_po)\n",
    "        np.save(f'{cache_dir}/o_po_align.npy', wp)\n",
    "        np.save(f'{cache_dir}/orch_start_end_frm.npy', np.array([orch_start_frm, orch_end_frm]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/o_chroma.npy'), f'o_chroma.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/po_chroma.npy'), f'po_chroma.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/o_po_align.npy'), f'o_po_align.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/orch_start_end_frm.npy'), f'orch_start_end_frm.npy missing from {indir}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "# Online Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cedd6f21",
   "metadata": {},
   "source": [
    "In the online processing stage, we do the following:\n",
    "1. compute an initial P-PO alignment using subsequence DTW with chroma features\n",
    "2. Fix the P-PO alignment and re-estimate the O-PO alignment.  This is done by adding P features to the O features based on the P-PO alignment, estimating the PO - O_plus_P alignment, and then inferring the P-O alignment.\n",
    "3. Fix the O-PO alignment and re-estimate the P-PO alignment.  This is done by adding O features to the P features based on the O-PO alignment, estimating the PO - P_plus_O alignment, and then inferring the P-O alignment.\n",
    "4. Repeat steps 2 & 3 until convergence\n",
    "\n",
    "Note that we save the estimated P-O alignment at each iteration so we can track performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(scenario_dir, out_dir, cache_dir, hop_length, steps, weights, numIters):\n",
    "    '''\n",
    "    Carries out `online' processing for a simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    out_dir: The directory to put results, intermediate files, and logging info\n",
    "    cache_dir: The cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "    numIters: number of iterations to run the algorithm\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    \n",
    "    # verify & setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "    # compute features\n",
    "    p_file = f'{scenario_dir}/p.wav'\n",
    "    y, sr = lb.core.load(p_file)\n",
    "    F_p = lb.feature.chroma_cqt(y=y, sr=sr, hop_length=hop_length, norm=None)  # piano features\n",
    "    F_po = np.load(f'{cache_dir}/po_chroma.npy') # full mix features\n",
    "    F_o = np.load(f'{cache_dir}/o_chroma.npy') # orchestra features\n",
    "    orch_start_frm, orch_end_frm = np.load(f'{cache_dir}/orch_start_end_frm.npy')\n",
    "        \n",
    "    # precomputed PO-O alignment\n",
    "    hop_sec = hop_length / sr\n",
    "    wp_BC = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "    wp_BC = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC)) # prepend (0,0) to handle edge cases properly\n",
    "\n",
    "    # compute P-PO alignment\n",
    "    C = 1 - lb.util.normalize(F_p, norm=2, axis=0).T @ lb.util.normalize(F_po, norm=2, axis=0)\n",
    "    _, _, wp_AB = dtw.dtw(C, steps, weights, True)\n",
    "\n",
    "    # infer piano-orchestra alignment\n",
    "    wp_AC = align_tools.infer_alignment(wp_AB, wp_BC, frames=True)\n",
    "    np.save(f'{out_dir}/hyp0.npy', wp_AC*hop_sec)\n",
    "\n",
    "    # re-estimation\n",
    "    for i in range(numIters):\n",
    "\n",
    "        if i%2 == 0:\n",
    "            \n",
    "            ### re-estimate PO-O alignment ###\n",
    "\n",
    "            # add P features to O features according to current P-PO alignment\n",
    "            F_o_mod = np.copy(F_o)\n",
    "            F_p_warped = isa.time_stretch_part(F_p, F_o, wp_AC.astype(np.int64).T) # alignment path must only contain integers\n",
    "            F_o_mod += F_p_warped\n",
    "\n",
    "            # estimate PO - O_plus_P alignment\n",
    "            C = 1 - lb.util.normalize(F_o_mod[:,orch_start_frm:orch_end_frm], norm=2, axis=0).T @ lb.util.normalize(F_po, norm=2, axis=0)\n",
    "            wp_BC = np.flipud(align_tools.compute_dtw_alignment(C, np.array([[1,1],[1,2],[2,1]]), [1,1,2], subseq = True)) # PO - O\n",
    "            wp_BC[1,:] = wp_BC[1,:] + orch_start_frm  # account for offset\n",
    "            wp_BC = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC)) # prepend (0,0) to handle TSM properly\n",
    "\n",
    "            # infer P - O alignment\n",
    "            wp_AC = align_tools.infer_alignment(wp_AB, wp_BC, frames=True)\n",
    "            np.save(f'{out_dir}/hyp{i+1}.npy', wp_AC*hop_sec)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            ### re-estimate P-PO alignment ###\n",
    "\n",
    "            # add O features to P features according to current O-PO alignment\n",
    "            F_p_mod = np.copy(F_p)\n",
    "            F_o_warped = isa.time_stretch_part(F_o, F_p, np.flipud(wp_AC.astype(np.int64)).T)# alignment path must only contain integers\n",
    "            F_p_mod += F_o_warped\n",
    "\n",
    "            # estimate P_plus_O - PO alignment\n",
    "            C = 1 - lb.util.normalize(F_p_mod, norm=2, axis=0).T @ lb.util.normalize(F_po, norm=2, axis=0)\n",
    "            wp_AB = align_tools.compute_dtw_alignment(C, np.array([[1,1],[1,2],[2,1]]), [1,1,2], subseq = True) # P - PO\n",
    "\n",
    "            # infer P - O alignment\n",
    "            wp_AC = align_tools.infer_alignment(wp_AB, wp_BC, frames=True)\n",
    "            np.save(f'{out_dir}/hyp{i+1}.npy', wp_AC*hop_sec)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19710221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp0.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "\n",
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s2'\n",
    "# out_dir = 'experiments/test/s2'\n",
    "# cache_dir = 'experiments/test/cache'\n",
    "# hop_size = 512\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3])\n",
    "# offline_processing(scenario_dir, cache_dir, hop_size, steps, weights)\n",
    "# online_processing(scenario_dir, out_dir, cache_dir, hop_size, steps, weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PianoConcertoAccompaniment",
   "language": "python",
   "name": "pianoconcertoaccompaniment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
