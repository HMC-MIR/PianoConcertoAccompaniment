{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# Simple Offline DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook implements a simple offline DTW baseline system.  The only requirement in this notebook is that it implement the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`.  The rest of the notebook is for experimenting, visualizing, and analyzing the system, so it should be thought of as a sandbox for development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6b5de",
   "metadata": {},
   "source": [
    "Here is a summary of the offline DTW approach:\n",
    "- Offline processing: The orchestra and full mix recordings are aligned with standard DTW using chroma features.\n",
    "- Online processing: The solo piano and full mix recordings are aligned with standard DTW using chroma features, and the predicted alignment is then used to infer the corresponding alignment between the piano and orchestra recordings.  Note that this approach is not actually a valid online approach -- it serves primarily as a reference to gauge the effectiveness of other approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610e1142",
   "metadata": {},
   "source": [
    "In the offline processing stage, three things are computed and stored in the `cache/` folder:\n",
    "- chroma features for the orchestra recording\n",
    "- chroma features for the full mix recording\n",
    "- predicted DTW alignment between the orchestra and full mix recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "import os.path\n",
    "import import_ipynb\n",
    "import align_tools\n",
    "import system_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length, steps, weights):\n",
    "    '''\n",
    "    Carries out offline processing for a simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    cache_dir: The location of the cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    \n",
    "    # setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    if os.path.exists(cache_dir):\n",
    "        print(f'{cache_dir} has already been processed.  Skipping.')\n",
    "        pass\n",
    "    else:\n",
    "        # setup\n",
    "        os.makedirs(cache_dir)\n",
    "\n",
    "        # compute orchestra features\n",
    "        o_file = f'{scenario_dir}/o.wav'\n",
    "        y_o, sr = lb.core.load(o_file)\n",
    "        F_o = lb.feature.chroma_cqt(y_o, sr=sr, hop_length=hop_length, norm=2) \n",
    "\n",
    "        # compute full mix features\n",
    "        po_file = f'{scenario_dir}/po.wav'\n",
    "        y_po, sr = lb.core.load(po_file)\n",
    "        F_po = lb.feature.chroma_cqt(y_po, sr=sr, hop_length=hop_length, norm=2)\n",
    "      \n",
    "        # compute subsequence DTW alignment (orchestra as query) \n",
    "        orch_start_sec, orch_end_sec = system_utils.get_orchestra_start_end_times(scenario_dir)\n",
    "        orch_start_frm = int(np.round(orch_start_sec * sr / hop_length))\n",
    "        orch_end_frm = int(np.round(orch_end_sec * sr / hop_length)) + 1\n",
    "        wp = align_tools.compute_dtw_alignment(1 - F_o[:,orch_start_frm:orch_end_frm].T @ F_po, steps, weights, subseq = True)\n",
    "        wp[0,:] = wp[0,:] + orch_start_frm  # account for offset\n",
    "\n",
    "        # save to cache\n",
    "        np.save(f'{cache_dir}/o_chroma.npy', F_o)\n",
    "        np.save(f'{cache_dir}/po_chroma.npy', F_po)\n",
    "        np.save(f'{cache_dir}/o_po_align.npy', wp)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/o_chroma.npy')\n",
    "    assert os.path.exists(f'{indir}/po_chroma.npy')\n",
    "    assert os.path.exists(f'{indir}/o_po_align.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "# Online Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd6f21",
   "metadata": {},
   "source": [
    "In the online processing stage, we do two things:\n",
    "- compute an offline DTW alignment between the piano and full mix recordings,\n",
    "- use the predicted alignment to infer the alignment between the piano and orchestra recordings\n",
    "\n",
    "Note that this baseline system is not a valid online system since it uses offline DTW.  It merely serves as a reference comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93981b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fsve_dtw_alignment(F1, F2, steps, weights):\n",
    "    '''\n",
    "    Computes a fixed start & variable end DTW alignment.  This is a hybrid of regular DTW\n",
    "    and subsequence DTW where the alignment path must start at the beginning of the reference,\n",
    "    but it may end anywhere in the reference.\n",
    "    \n",
    "    Inputs\n",
    "    F1: Feature matrix for first recording (query), specified as a 12 x N matrix\n",
    "    F2: Feature matrix for second recording (reference), specified as a 12 x M matrix\n",
    "    steps: L x 2 numpy array specifying the allowable DTW transitions\n",
    "    weights: length L array specifying the DTW transition weights\n",
    "    \n",
    "    Returns the estimated alignment path, specified as a K x 2 numpy array.\n",
    "    '''\n",
    "    \n",
    "    # dynamic programming is computed like regular DTW\n",
    "    C = 1 - F1.T @ F2 # cos distance metric\n",
    "    dn = steps[:,0].astype(np.uint32)\n",
    "    dm = steps[:,1].astype(np.uint32)\n",
    "    parameters_dp = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': False}\n",
    "    [D, s] = align_tools.DTW_Cost_To_AccumCostAndSteps(C, parameters_dp)\n",
    "    \n",
    "    # but backtracking is performed like subsequence DTW\n",
    "    parameters_backtrack = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': True}\n",
    "    [wp, endCol, endCost] = align_tools.DTW_GetPath(D, s, parameters_backtrack)\n",
    "\n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(scenario_dir, out_dir, cache_dir, hop_length, steps, weights):\n",
    "    '''\n",
    "    Carries out `online' processing for a simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    out_dir: The directory to put results, intermediate files, and logging info\n",
    "    cache_dir: The cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    \n",
    "    # verify & setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "    # compute features\n",
    "    p_file = f'{scenario_dir}/p.wav'\n",
    "    y, sr = lb.core.load(p_file)\n",
    "    F_p = lb.feature.chroma_cqt(y, sr=sr, hop_length=hop_length, norm=2)  # piano features\n",
    "    F_po = np.load(f'{cache_dir}/po_chroma.npy') # full mix features\n",
    "        \n",
    "    # determine the start time of the query in the orchestra recording (ground truth)\n",
    "    hop_sec = hop_length / sr\n",
    "    orch_start_sec, _ = system_utils.get_orchestra_query_boundaries(scenario_dir)\n",
    "    orch_start_frm = orch_start_sec / hop_sec  # keep max precision, don't round\n",
    "    \n",
    "    # infer the start time of the query in the full mix recording (estimated)\n",
    "    wp_BC = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "    wp_BC = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC)) # prepend (0,0) to handle edge cases properly\n",
    "    fullmix_start_frm = int(np.round(np.interp(orch_start_frm, wp_BC[1,:], wp_BC[0,:])))\n",
    "    \n",
    "    # force the DTW alignment to start at the correct position\n",
    "    wp_AB = compute_fsve_dtw_alignment(F_p, F_po[:,fullmix_start_frm:], steps, weights)\n",
    "    wp_AB[1,:] = wp_AB[1,:] + fullmix_start_frm  # compensate for offset\n",
    "    \n",
    "    # infer piano-orchestra alignment\n",
    "    wp_AC = align_tools.infer_alignment(wp_AB, wp_BC, frames=True)\n",
    "    np.save(f'{out_dir}/hyp.npy', wp_AC*hop_sec)\n",
    "    \n",
    "    # save debugging info\n",
    "    np.save(f'{out_dir}/orch_start_sec.npy', orch_start_sec)\n",
    "    np.save(f'{out_dir}/fullmix_start_frm.npy', fullmix_start_frm)\n",
    "    np.save(f'{out_dir}/p_po_align.npy', wp_AB)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19710221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s2'\n",
    "# out_dir = 'experiments/test/s2'\n",
    "# cache_dir = 'experiments/test/cache'\n",
    "# hop_size = 512\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3])\n",
    "# offline_processing(scenario_dir, cache_dir, hop_size, steps, weights)\n",
    "# online_processing(scenario_dir, out_dir, cache_dir, hop_size, steps, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13cef25",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc1aa6",
   "metadata": {},
   "source": [
    "Some code for debugging the system.  Can delete later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a631ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s2'\n",
    "# out_dir = 'experiments/debug/s2'\n",
    "# cache_dir = 'experiments/debug/cache'\n",
    "# hop_length = 512\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6320614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#offline_processing(scenario_dir, cache_dir, hop_length, steps, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20dbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9538df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_file = f'{scenario_dir}/p.wav'\n",
    "# y, sr = lb.core.load(p_file)\n",
    "# F_p = lb.feature.chroma_cqt(y, sr=sr, hop_length=hop_length, norm=2)  # piano features\n",
    "# F_po = np.load(f'{cache_dir}/po_chroma.npy') # full mix features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbd15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orch_start_sec, _ = get_orchestra_query_boundaries(scenario_dir)\n",
    "# orch_start_frm = orch_start_sec / (hop_length / sr)  # keep max precision, don't round\n",
    "# # infer the start time of the query in the full mix recording (estimated)\n",
    "# wp_BC = np.load(f'{cache_dir}/po_o_align.npy')\n",
    "# fullmix_start_frm = int(np.round(np.interp(orch_start_frm, wp_BC[1,:], wp_BC[0,:])))\n",
    "# # force the DTW alignment to start at the correct position\n",
    "# wp_AB = compute_fsve_dtw_alignment(F_p, F_po[:,fullmix_start_frm:], steps, weights)\n",
    "# wp_AB[1,:] = wp_AB[1,:] + fullmix_start_frm  # compensate for offset\n",
    "# # infer piano-orchestra alignment\n",
    "# wp_AC = infer_alignment(wp_AB, wp_BC)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(wp_AC[0,:]*hop_sec, wp_AC[1,:]*hop_sec)\n",
    "# plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accompaniment",
   "language": "python",
   "name": "accompaniment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
