{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# Mixture 3D Subsequence DTW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook implements an offline Mixture 3D Subsequence DTw approach.  Running this algorithm requires installing some other software, which is described below.  This notebook implements the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`.\n",
    "\n",
    "Our main findings are:\n",
    "- Because this algorithm performs DTW on a 3D cost tensor, it is computationally expensive.  This forced us to use highly downsampled features in order to achieve reasonable runtimes.\n",
    "- With the downsampled features, we did not see any promising results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb328e",
   "metadata": {},
   "source": [
    "In the offline processing stage, two things are computed and stored in the `cache/` folder:\n",
    "- chroma features for the orchestra recording\n",
    "- chroma features for the full mix recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import system_utils\n",
    "import align_tools\n",
    "import sonify_tools\n",
    "import os\n",
    "import os.path\n",
    "import subprocess\n",
    "import librosa as lb\n",
    "from shutil import which\n",
    "from hmc_mir.align import dtw\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange\n",
    "import k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length=2048, downsample=10):\n",
    "    '''\n",
    "    Carries out the same offline processing steps as the simple offline DTW system.\n",
    "    \n",
    "    Args:\n",
    "        scenario_dir: The scenario directory to process\n",
    "        cache_dir: The location of the cache directory\n",
    "        hop_length: The hop length in samples used when computing chroma features\n",
    "        downsample: The downsampling factor used when computing chroma_sens features\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    # setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    if os.path.exists(cache_dir):\n",
    "        # print(f'{cache_dir} has already been processed.  Skipping.')\n",
    "        pass\n",
    "    else:\n",
    "        # setup\n",
    "        os.makedirs(cache_dir)\n",
    "        \n",
    "        o_file = f'{scenario_dir}/o.wav'\n",
    "        y_o, sr = lb.core.load(o_file)\n",
    "        F_o = lb.feature.chroma_cens(y=y_o, sr=sr, hop_length=hop_length)\n",
    "        F_o = F_o[:,::downsample]\n",
    "\n",
    "        po_file = f'{scenario_dir}/po.wav'\n",
    "        y_po, sr = lb.core.load(po_file)\n",
    "        F_po = lb.feature.chroma_cens(y=y_po, sr=sr, hop_length=hop_length)\n",
    "        F_po = F_po[:,::downsample]\n",
    "\n",
    "        np.save(f'{cache_dir}/po_cqt.npy', F_po / np.linalg.norm(F_po, axis=0))\n",
    "        np.save(f'{cache_dir}/o_cqt.npy', F_o / np.linalg.norm(F_o, axis=0))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fcf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/po_cqt.npy'), f'missing {indir}/po_cqt.npy'\n",
    "    assert os.path.exists(f'{indir}/o_cqt.npy'), f'missing {indir}/o_cqt.npy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "## Online Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb3077-3cc9-4259-ac6f-f772ff928265",
   "metadata": {},
   "source": [
    "In the online processing stage, we do the following:\n",
    "- We perform pairwise alignment between the P and PO recordings using standard subsequence DTw with chroma features.  This allows us to identify the matching portion of the PO recording.\n",
    "- We then perform a 3D subsequence DTW alignment among P, PO-match, and the complete O recording using a mixture-based cost (dissimilarity between P+O and PO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d865c60",
   "metadata": {},
   "source": [
    "### Wrapper Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(\n",
    "    scenario_dir,\n",
    "    out_dir,\n",
    "    cache_dir,\n",
    "    hop_length=2048,\n",
    "    downsample=10,\n",
    "    steps=np.array([[0,0,1],[1,1,1],[1,2,1],[2,1,1]]),\n",
    "    weights=[0,1,1,2],\n",
    "    match_buffer = 10\n",
    "):\n",
    "    '''\n",
    "    Carries out `online' processing using the ISA algorithm.\n",
    "    \n",
    "    Args:\n",
    "        scenario_dir: The scenario directory to process\n",
    "        out_dir: The directory to put results, intermediate files, and logging info\n",
    "        cache_dir: The cache directory\n",
    "        hop_length: The hop length in samples used when computing cqt features\n",
    "        downsample: The downsampling factor used when computing chroma_sens features\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    \n",
    "    # verify & setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "    scenario_info = system_utils.get_scenario_info(scenario_dir+'/scenario.info')\n",
    "    \n",
    "    p_file = f'{scenario_dir}/p.wav'\n",
    "    y, sr = lb.core.load(p_file)\n",
    "\n",
    "    F_p = lb.feature.chroma_cens(y=y, sr=sr, hop_length=hop_length)[:,::downsample]\n",
    "    F_p = F_p / np.linalg.norm(F_p, axis=0)\n",
    "    F_po = np.load(f'{cache_dir}/po_cqt.npy') # full mix features\n",
    "    F_o = np.load(f'{cache_dir}/o_cqt.npy') # orchestra\n",
    "    \n",
    "    F_p = np.nan_to_num(F_p)\n",
    "    F_o = np.nan_to_num(F_o)\n",
    "    F_po = np.nan_to_num(F_po)\n",
    "\n",
    "    hop_sec = downsample * hop_length / sr\n",
    "\n",
    "    C = 1 - (F_p.T @ F_po)\n",
    "    D, B, path = dtw.dtw(C, np.array([[1,1],[1,2],[2,1]]),[1,1,2], True)\n",
    "    F_po_match = F_po[:, max(path[1,0]-match_buffer, 0):min(path[1,-1]+match_buffer, F_po.shape[1])]\n",
    "\n",
    "    best_cost, path = dtw3d(F_p, F_o, F_po_match, steps, weights)\n",
    "\n",
    "    \n",
    "    # infer piano-orchestra alignment\n",
    "    wp_AC = np.vstack((path[0],path[1]))\n",
    "    wp_AC[1, :] -= match_buffer\n",
    "    wp_AC_sec = wp_AC*hop_sec\n",
    "    wp_AC_sec[1,:] += scenario_info['oStart']\n",
    "    np.save(f'{out_dir}/hyp.npy', wp_AC_sec)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp.npy'), f'{indir} is missing the required files, please re run the online processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def calculate_cost_tensor(x, y, z):\n",
    "    '''\n",
    "    Calculates the cost tensor for the given piano, orchestra, and piano-orchestra features.\n",
    "    \n",
    "    Args:\n",
    "        x: submix features\n",
    "        y: submix features\n",
    "        z: full mix features\n",
    "    '''\n",
    "    x = x.T\n",
    "    y = y.T\n",
    "    z = z.T\n",
    "    cost_tensor = np.zeros((x.shape[0], y.shape[0], z.shape[0]))\n",
    "    for i in prange(x.shape[0]):\n",
    "        for j in prange(y.shape[0]):\n",
    "            for k in prange(z.shape[0]):\n",
    "                cost_tensor[i, j, k] = 1 - (np.dot(z[k,:], x[i,:] + y[j,:]) / (np.linalg.norm(z[k,:]) * np.linalg.norm(x[i,:] + y[j,:])))\n",
    "    cost_tensor = np.swapaxes(cost_tensor, 1, 2)\n",
    "    return cost_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ef406",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def backtrace_flexdtw(D, B, steps, rstart, cstart, tstart):\n",
    "    '''\n",
    "    Backtraces through the cumulative cost matrix D starting from a specified location.\n",
    "    \n",
    "    Arguments:\n",
    "    D: cumulative cost matrix\n",
    "    B: backtrace matrix\n",
    "    steps: a numpy matrix specifying the allowable transitions.  It should be of\n",
    "            dimension (L, 2), where each row specifies (row step, col step)\n",
    "    rstart: the row index to start backtracking from\n",
    "    cstart: the column index to start backtracking from\n",
    "    \n",
    "    Outputs\n",
    "    path: a python list of (row, col) coordinates for the optimal path.\n",
    "    '''\n",
    "    pos = (rstart, cstart, tstart)\n",
    "    path = []\n",
    "    path.append(pos)\n",
    "    while(pos[0] != 0 and pos[1] != 0 and pos[2] != 0):\n",
    "        (row, col, tube) = pos\n",
    "        stepidx = B[row, col, tube]\n",
    "        (rstep, cstep, tstep) = steps[stepidx]\n",
    "        pos = (row-rstep, col-cstep, tube-tstep)\n",
    "        path.append(pos)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88355151",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def find_best_endpoint(D, P, buffer):\n",
    "    '''\n",
    "    Determines the best location to begin backtracking from by comparing the average path cost\n",
    "    per manhattan block.\n",
    "    \n",
    "    Inputs\n",
    "    D: the cumulative cost matrix\n",
    "    P: the matrix specifying the starting location of the alignment path\n",
    "    buffer: specifies the length of a buffer region (in frames) to avoid short degenerate alignment paths\n",
    "        near the corners of the pairwise cost matrix.  This can be thought of as the minimum length that\n",
    "        needs to match in order to be considered a valid alignment path.\n",
    "    \n",
    "    Outputs\n",
    "    best_cost: the best average path cost per manhattan block\n",
    "    best_r: the row index of the best endpoint\n",
    "    best_c: the column index of the best endpoint\n",
    "    debug: debugging information for examining the average cost per manhattan block for each \n",
    "        of the candidate ending positions\n",
    "    '''\n",
    "    \n",
    "    # consider the top corner 3 faces as candidates\n",
    "    candidates = []\n",
    "    for i in range(buffer, D.shape[0]):\n",
    "        for j in range(buffer, D.shape[1]):\n",
    "            candidates.append((i, j, D.shape[2]-1))\n",
    "\n",
    "    for j in range(buffer, D.shape[1]):\n",
    "        for k in range(buffer, D.shape[2]):\n",
    "            candidates.append((D.shape[0]-1, j, k))\n",
    "\n",
    "    for i in range(buffer, D.shape[0]):\n",
    "        for k in range(buffer, D.shape[2]):\n",
    "            candidates.append((i, D.shape[1]-1, k))\n",
    "    \n",
    "    best_cost = np.inf\n",
    "    best_r, best_c, best_t = -1, -1, -1\n",
    "    # debug = []\n",
    "    debug = np.zeros_like(D)\n",
    "    \n",
    "    for i, (r,c,t) in enumerate(candidates):\n",
    "                \n",
    "        # get alignment start location\n",
    "        rstart, cstart, tstart = P[r,c,t]\n",
    "            \n",
    "        # calculate average cost per manhattan block\n",
    "        mdist = (r - rstart) + (c - cstart) + (t - tstart)# manhattan distance\n",
    "        avg_cost_per_mb = D[r,c,t] / mdist\n",
    "        \n",
    "        # keep best\n",
    "        if avg_cost_per_mb < best_cost:\n",
    "            best_cost = avg_cost_per_mb\n",
    "            best_r, best_c, best_t = r, c, t\n",
    "            \n",
    "        # debugging info\n",
    "        # TODO: updated this for 3D-FlexDTW\n",
    "        # if r == D.shape[0]-1:\n",
    "        #     debug.append((c-D.shape[1]+1, avg_cost_per_mb, r, c))\n",
    "        # else:\n",
    "        #     debug.append((D.shape[0]-1-r, avg_cost_per_mb, r, c))\n",
    "        debug[r,c,t] = avg_cost_per_mb\n",
    "    \n",
    "    return best_cost, best_r, best_c, best_t, debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d02a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def dtw3d(x, y, z, steps, weights):\n",
    "    C = calculate_cost_tensor(x, y, z)\n",
    "    \n",
    "    # Run FlexDTW on the cost tensor\n",
    "    D = np.ones(C.shape) * np.inf\n",
    "    B = np.zeros(C.shape, dtype=np.int8)\n",
    "\n",
    "    # D[0, :, :] = np.inf\n",
    "    # D[:, 0, :] = np.inf\n",
    "    # D[:, :, 0] = np.inf\n",
    "    # for row in range(1,C.shape[0]):\n",
    "    #     for col in range(1, C.shape[1]):\n",
    "    #         for tube in range (1, C.shape[2]):\n",
    "    #             D[row, col, tube] = -np.inf\n",
    "    # D[0,0,0] = C[0,0,0]\n",
    "    D[0,:,:] = C[0,:,:]\n",
    "\n",
    "    # DP\n",
    "    for row in range(1,C.shape[0]):\n",
    "        for col in range(1, C.shape[1]):\n",
    "            for tube in range (1, C.shape[2]):\n",
    "                mincost = np.inf\n",
    "                minidx = -1\n",
    "                bestrprev = -1\n",
    "                bestcprev = -1\n",
    "                besttprev = -1\n",
    "                for stepidx, step in enumerate(steps):\n",
    "                    (rstep, cstep, tstep) = step\n",
    "                    prevrow = row - rstep\n",
    "                    prevcol = col - cstep\n",
    "                    prevtube = tube - tstep\n",
    "                    if prevrow >= 0 and prevcol >= 0 and prevtube >= 0:\n",
    "                        \n",
    "                        pathcost = D[prevrow, prevcol, prevtube] + C[row, col, tube] * weights[stepidx]\n",
    "                        \n",
    "                        if pathcost < mincost:\n",
    "                            mincost = pathcost\n",
    "                            minidx = stepidx\n",
    "                            bestrprev = prevrow\n",
    "                            bestcprev = prevcol\n",
    "                            besttprev = prevtube\n",
    "                            \n",
    "                D[row, col, tube] = D[bestrprev, bestcprev, besttprev] + C[row, col, tube] * weights[minidx]\n",
    "                B[row, col, tube] = minidx\n",
    "\n",
    "    best_cost = np.inf\n",
    "    bestr = C.shape[0]-1\n",
    "    bestc = -1\n",
    "    bestt = -1\n",
    "    for col in range(C.shape[1]):\n",
    "        for tube in range(C.shape[2]):\n",
    "            if D[bestr, col, tube] < best_cost:\n",
    "                best_cost = D[bestr, col, tube]\n",
    "                bestc = col\n",
    "                bestt = tube\n",
    "\n",
    "    path = backtrace_flexdtw(D, B, steps, bestr, bestc, bestt)\n",
    "    path.reverse()\n",
    "    path = np.array(path)\n",
    "\n",
    "    return best_cost, path.T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# online_processing('scenarios/s1', 'experiments/mixtureDTW/s1', 'experiments/mixtureDTW/cache/rach2_mov1_O1_PO1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aef5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dir = 'scenarios/s12'\n",
    "hop_length = 512\n",
    "downsample = 10\n",
    "#match_buffer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc7fc3-354c-4924-9e9c-a64a43fd1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract O, PO features\n",
    "o_file = f'{scenario_dir}/o.wav'\n",
    "y_o, sr = lb.core.load(o_file)\n",
    "F_o = lb.feature.chroma_cens(y=y_o, sr=sr, hop_length=hop_length)\n",
    "F_o = F_o[:,::downsample]\n",
    "# F_o = F_o / np.linalg.norm(F_o, axis=0)\n",
    "\n",
    "po_file = f'{scenario_dir}/po.wav'\n",
    "y_po, sr = lb.core.load(po_file)\n",
    "F_po = lb.feature.chroma_cens(y=y_po, sr=sr, hop_length=hop_length)\n",
    "F_po = F_po[:,::downsample]\n",
    "# F_po = F_po / np.linalg.norm(F_po, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbd2c8-7737-4622-ae07-84317c86a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract P features\n",
    "p_file = f'{scenario_dir}/p.wav'\n",
    "y_p, sr = lb.core.load(p_file)\n",
    "F_p = lb.feature.chroma_cens(y=y_p, sr=sr, hop_length=hop_length)\n",
    "F_p = F_p[:,::downsample]\n",
    "# F_p = F_p / np.linalg.norm(F_p, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750d262-397c-46ca-b12d-a192df2187d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-select the matching region of PO\n",
    "hop_sec = downsample * hop_length / sr\n",
    "C = 1 - (F_p.T @ F_po)\n",
    "D, B, path = dtw.dtw(C, np.array([[1,1],[1,2],[2,1]]),[1,1,2], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3549a024-c784-44f2-800f-fff8a18580a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "po_match_start = path[1,0]\n",
    "po_match_end = path[1,-1] + 1\n",
    "F_po_match = F_po[:, po_match_start:po_match_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57facc8-c2d3-416f-a2a5-1f176d28ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_p.shape[1], F_o.shape[1], F_po_match.shape[1], F_po.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520f39f-37df-4f52-ad45-e2f9a8e5fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=np.array([[0,0,1],[1,1,1],[1,2,1],[2,1,1]])\n",
    "weights=[0.3,1.0,1.0,2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97f4e3-6243-4a53-b3af-2e6c95e48919",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cost, path = dtw3d(F_p, F_o, F_po_match, steps, weights) \n",
    "# path[0] --> P\n",
    "# path[1] --> PO\n",
    "# path[2] --> O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2809d-c184-4d7c-89c0-c7e1999884b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-O alignment\n",
    "wp_AC = np.vstack((path[0],path[2]))\n",
    "wp_AC_sec = wp_AC*hop_sec\n",
    "plt.plot(wp_AC_sec[0,:], wp_AC_sec[1,:])\n",
    "plt.xlabel('Piano (sec)')\n",
    "plt.ylabel('Orchestra (sec)')\n",
    "wp_AC_sec[1,0], wp_AC_sec[1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564ac4b-4e37-456b-a385-d8ee97f23332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PO-O alignment\n",
    "wp_BC = np.vstack((path[1],path[2]))\n",
    "wp_BC_sec = wp_BC*hop_sec\n",
    "plt.plot(wp_BC_sec[0,:], wp_BC_sec[1,:])\n",
    "plt.xlabel('Full Mix (sec)')\n",
    "plt.ylabel('Orchestra (sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb53f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-PO alignment\n",
    "wp_AB = np.vstack((path[0],path[1]))\n",
    "wp_AB_sec = wp_AB*hop_sec\n",
    "plt.plot(wp_AB_sec[0,:], wp_AB_sec[1,:])\n",
    "plt.xlabel('Piano (sec)')\n",
    "plt.ylabel('Full Mix (sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494f54f-2881-431c-8c20-3f4b5027fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_AC_sec[:,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f56d7-cc8e-4baf-a74d-2f37c32d3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "F_random = np.random.rand(12,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8716a5-d2ce-42d4-93f2-41b177a3c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_cost, path = dtw3d(F_random, F_random, F_random, steps, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ee477-134d-4bf7-bc13-6cabfaaca9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PianoConcertoAccompaniment",
   "language": "python",
   "name": "pianoconcertoaccompaniment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
