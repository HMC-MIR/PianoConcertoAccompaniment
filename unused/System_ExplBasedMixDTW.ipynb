{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# Explanation Based Mixture DTW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook implements an Explanation-Based 2D Mixture DTW.  The only requirement in this notebook is that it implement the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`.\n",
    "\n",
    "Our main findings:\n",
    "- We find that this approach is much slower than a naive pairwise DTW approach, and does not improve performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610e1142",
   "metadata": {},
   "source": [
    "In the offline processing stage, two things are computed and stored in the `cache/` folder:\n",
    "- chroma features for the orchestra recording\n",
    "- chroma features for the full mix recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "import os.path\n",
    "import import_ipynb\n",
    "import align_tools\n",
    "import system_utils\n",
    "from hmc_mir.align import dtw, isa\n",
    "from numba import jit, njit, prange\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length):\n",
    "    '''\n",
    "    Carries out offline processing for a simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    cache_dir: The location of the cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    \n",
    "    # setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    if os.path.exists(cache_dir):\n",
    "        # print(f'{cache_dir} has already been processed.  Skipping.')\n",
    "        pass\n",
    "    else:\n",
    "        # setup\n",
    "        os.makedirs(cache_dir)\n",
    "\n",
    "        # compute orchestra features\n",
    "        o_file = f'{scenario_dir}/o.wav'\n",
    "        y_o, sr = lb.core.load(o_file)\n",
    "        F_o = lb.feature.chroma_cqt(y=y_o, sr=sr, hop_length=hop_length, norm=None) \n",
    "\n",
    "        # compute full mix features\n",
    "        po_file = f'{scenario_dir}/po.wav'\n",
    "        y_po, sr = lb.core.load(po_file)\n",
    "        F_po = lb.feature.chroma_cqt(y=y_po, sr=sr, hop_length=hop_length, norm=None)\n",
    "      \n",
    "        # compute subsequence DTW alignment (orchestra as query) \n",
    "        orch_start_sec, orch_end_sec = system_utils.get_orchestra_start_end_times(scenario_dir)\n",
    "        orch_start_frm = int(np.round(orch_start_sec * sr / hop_length))\n",
    "        orch_end_frm = int(np.round(orch_end_sec * sr / hop_length)) + 1\n",
    "\n",
    "        # save to cache\n",
    "        np.save(f'{cache_dir}/o_chroma.npy', F_o)\n",
    "        np.save(f'{cache_dir}/po_chroma.npy', F_po)\n",
    "        np.save(f'{cache_dir}/orch_start_end_frm.npy', np.array([orch_start_frm, orch_end_frm]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/o_chroma.npy'), f'o_chroma.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/po_chroma.npy'), f'po_chroma.npy missing from {indir}'\n",
    "    #assert os.path.exists(f'{indir}/o_po_align.npy'), f'o_po_align.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/orch_start_end_frm.npy'), f'orch_start_end_frm.npy missing from {indir}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "# Online Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf5c43-7226-4212-a4e7-493a632168f7",
   "metadata": {},
   "source": [
    "In the online processing stage, we do the following:\n",
    "- compute the P-PO alignment using standard subsequence DTW with chroma features\n",
    "- find the matching PO segment and the corresponding P frames.  This establishes a baseline similarity when using only P features.\n",
    "- calculate a 2d cost matrix between the (matching) PO frames and O frames using a mixture-based cost.  This cost is computed by first re-weighting the features to ensure O and P features have roughly equal volume, adding the P and O features, and then comparing the sum to the corresponding PO frame\n",
    "- the final 2d cost matrix between PO and O is determined by calculating the difference between the baseline similarity (only using P features) and the mixture similarity (using both P and O features).  In essence, we are measuring how much using O features in addition to P features improves our ability to explain the PO features.\n",
    "- perform standard subsequence on this explanation-based cost matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(scenario_dir, out_dir, cache_dir, hop_length, steps, weights):\n",
    "    '''\n",
    "    Carries out `online' processing for a simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    out_dir: The directory to put results, intermediate files, and logging info\n",
    "    cache_dir: The cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    \n",
    "    # verify & setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "    # compute features\n",
    "    p_file = f'{scenario_dir}/p.wav'\n",
    "    y, sr = lb.core.load(p_file)\n",
    "    F_p = lb.feature.chroma_cqt(y=y, sr=sr, hop_length=hop_length, norm=None)  # piano features\n",
    "    F_po = np.load(f'{cache_dir}/po_chroma.npy') # full mix features\n",
    "    F_o = np.load(f'{cache_dir}/o_chroma.npy') # orchestra features\n",
    "    orch_start_frm, orch_end_frm = np.load(f'{cache_dir}/orch_start_end_frm.npy')\n",
    "\n",
    "    # compute P-PO alignment\n",
    "    C = 1 - lb.util.normalize(F_p, norm=2, axis=0).T @ lb.util.normalize(F_po, norm=2, axis=0)\n",
    "    _, _, wp_AB = dtw.dtw(C, steps, weights, True)\n",
    "    \n",
    "    # get aligned P & PO features (matching region only)\n",
    "    po_start_frm, po_end_frm = wp_AB[1,0], wp_AB[1,-1] + 1\n",
    "    F_po_match = F_po[:,po_start_frm:po_end_frm]\n",
    "    F_p_aligned = time_stretch_part(F_p, F_po, wp_AB.T)\n",
    "    F_p_aligned = F_p_aligned[:, po_start_frm:po_end_frm] # only keep matching portion\n",
    "    assert(F_po_match.shape == F_p_aligned.shape)\n",
    "\n",
    "    # baseline similarity between PO and P\n",
    "    F_po_match_norm = lb.util.normalize(F_po_match, axis=0, norm=2) # note: handles zeros properly\n",
    "    F_p_aligned_norm = lb.util.normalize(F_p_aligned, axis=0, norm=2)\n",
    "    baseline_similarity = np.sum(F_po_match_norm * F_p_aligned_norm, axis=0)\n",
    "\n",
    "    # similarity between PO and P_plus_O\n",
    "    p_vol_avg = np.sum(np.mean(F_p, axis=1))\n",
    "    o_vol_avg = np.sum(np.mean(F_o, axis=1))\n",
    "    mixture_similarity = np.zeros((F_po_match.shape[1], F_o.shape[1]))\n",
    "    # Note: this implementation uses a for loop to reduce memory usage\n",
    "    for i in range(F_po_match.shape[1]): \n",
    "        Frow_p_plus_o = F_p_aligned[:,i].reshape((-1,1)) * o_vol_avg / p_vol_avg + F_o # apply volume gain so O and P have roughly equal volume\n",
    "        mixture_similarity[i,:] = F_po_match_norm[:,i].reshape((1,-1)) @ lb.util.normalize(Frow_p_plus_o, axis=0, norm=2)\n",
    "\n",
    "    # compute PO - P_plus_O alignment\n",
    "    Cdiff = baseline_similarity.reshape(-1,1) - mixture_similarity\n",
    "    _, _, wp_BC = dtw.dtw(Cdiff, steps, weights, True)\n",
    "    wp_BC[0,:] = wp_BC[0,:] + po_start_frm  # account for offset\n",
    "\n",
    "    # infer piano-orchestra alignment\n",
    "    hop_sec = hop_length / sr\n",
    "    wp_AC = align_tools.infer_alignment(wp_AB, wp_BC, frames=True)\n",
    "    np.save(f'{out_dir}/hyp.npy', wp_AC*hop_sec)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7babd8f-833c-4c64-a71a-c85e6c3e3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist_safe(F1, F2):\n",
    "    '''\n",
    "    Calculates the pairwise cos distance between two features matrices.  Handles zero magnitudes safely.\n",
    "    '''\n",
    "    C = 1 - lb.util.normalize(F_o_mod, norm=2, axis=0).T @ lb.util.normalize(F_po, norm=2, axis=0)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4287a-4dff-4c4d-98af-31fb6fb5a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch_part(query, ref, alignment):\n",
    "    \"\"\"Uses the alignment computed from DTW to time stretch the query to have the same dimensions as the reference.\n",
    "    \n",
    "    Args:\n",
    "        query (np.ndarray): The features of the part\n",
    "        ref (np.ndarray): The features of the full mix\n",
    "        alignment (np.ndarray): The alignment between the part and full mix, shape L x 2\n",
    "    \n",
    "    Returns:\n",
    "        feature_stretch (np.ndarray): The time stretched part\n",
    "    \"\"\"\n",
    "    m, n = ref.shape\n",
    "    feature_stretch = np.zeros((m, n))\n",
    "    used = set(alignment[:, 1])\n",
    "    for query_idx, ref_idx in alignment:\n",
    "        feature_stretch[:, ref_idx] = query[:, query_idx]\n",
    "    ref_start_frm, ref_end_frm = alignment[0,1], alignment[-1,1] + 1\n",
    "    for j in range(ref_start_frm + 1, ref_end_frm - 1):\n",
    "        if j not in used:\n",
    "            feature_stretch[:, j] = 0.5 * (feature_stretch[:,j-1] + feature_stretch[:,j+1])\n",
    "    return feature_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19710221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "\n",
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s2'\n",
    "# out_dir = 'experiments/test/s2'\n",
    "# cache_dir = 'experiments/test/cache'\n",
    "# hop_size = 512\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3])\n",
    "# offline_processing(scenario_dir, cache_dir, hop_size, steps, weights)\n",
    "# online_processing(scenario_dir, out_dir, cache_dir, hop_size, steps, weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PianoConcertoAccompaniment",
   "language": "python",
   "name": "pianoconcertoaccompaniment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
