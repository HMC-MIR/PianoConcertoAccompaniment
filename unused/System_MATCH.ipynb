{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# MATCH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook provides wrapper functions for calling the [MATCH algorithm](https://www.eecs.qmul.ac.uk/~simond/match/).  Running this algorithm requires installing some other software, which is described below.  This notebook implements the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ff6b5de",
   "metadata": {},
   "source": [
    "Here is a summary of the MATCH approach:\n",
    "- Offline processing: The orchestra and full mix recordings are aligned with standard DTW using chroma features.\n",
    "- Online processing: The solo piano and full mix recordings are aligned with the MATCH algorithm, and the predicted alignment is then used to infer the corresponding alignment between the piano and orchestra recordings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c98c2-df89-46d4-b05a-44f770360186",
   "metadata": {},
   "source": [
    "Because we are switching to a purely offline formulation of the alignment problem, this approach is deprecated (replaced with NaivePairwiseDTW)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610e1142",
   "metadata": {},
   "source": [
    "The offline processing is the same as in the simple offline DTW system.  In the offline processing stage, three things are computed and stored in the `cache/` folder:\n",
    "- chroma features for the orchestra recording\n",
    "- chroma features for the full mix recording\n",
    "- predicted DTW alignment between the orchestra and full mix recordings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import System_OfflineDTW\n",
    "import system_utils\n",
    "import align_tools\n",
    "import sonify_tools\n",
    "import os\n",
    "import os.path\n",
    "import subprocess\n",
    "import librosa as lb\n",
    "import vamp\n",
    "from shutil import which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length, steps, weights):\n",
    "    '''\n",
    "    Carries out the same offline processing steps as the simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    cache_dir: The location of the cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    System_OfflineDTW.offline_processing(scenario_dir, cache_dir, hop_length, steps, weights)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fcf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/o_chroma.npy'), f'missing {indir}/o_chroma.npy'\n",
    "    assert os.path.exists(f'{indir}/po_chroma.npy'), f'missing {indir}/po_chroma.npy'\n",
    "    assert os.path.exists(f'{indir}/o_po_align.npy'), f'missing {indir}/o_po_align.npy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "## Online Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cedd6f21",
   "metadata": {},
   "source": [
    "In the online processing stage, we do two things:\n",
    "1. compute an online alignment between the piano and full mix recordings using MATCH,\n",
    "2. use the predicted alignment to infer the alignment between the piano and orchestra recordings\n",
    "\n",
    "Note that step 1 is completed before we begin step 2.  This implementation is thus not a valid online system, but its performance nonetheless can tell us how well an online system would perform."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "953b48e1",
   "metadata": {},
   "source": [
    "### Software Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a7a73c8",
   "metadata": {},
   "source": [
    "Using the MATCH algorithm requires a few pieces of software to be installed:\n",
    "- [Sonic Annotator](https://vamp-plugins.org/sonic-annotator/), a program for command-line processing of audio files\n",
    "- [the MATCH Vamp plugin](https://code.soundsoftware.ac.uk/projects/match-vamp/), an implementation of the MATCH algorithm which can be used in tandem with Sonic Annotator\n",
    "- the SoX command line audio utility tool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07bac0c7",
   "metadata": {},
   "source": [
    "Below, we will assume that the `sonic-annotator` and `sox` binaries can be called from command line, and that the MATCH Vamp plugin has been installed.  See [here](https://vamp-plugins.org/download.html#install) for instructions on how to install Vamp plugins."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d865c60",
   "metadata": {},
   "source": [
    "### Wrapper Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee807a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_match_installation():\n",
    "    '''Verifies that all tools need to run MATCH are present\n",
    "    '''\n",
    "\n",
    "    assert which('sox') is not None, '`sox` is not installed. Please see System_MATCH.ipynb for installation instructions'\n",
    "    assert which('sonic-annotator') is not None, '`sonic-annotator` is not installed. Please see System_MATCH.ipynb for installation instructions'\n",
    "\n",
    "    result = subprocess.run(['sonic-annotator', '-l'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    assert 'vamp:match-vamp-plugin' in result.stdout.decode('utf-8'), '`sonic-annotator` is installed but the MATCH plugin is not. Please see System_MATCH.ipynb for installation instructions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_match_outfile(infile):\n",
    "    '''\n",
    "    Parses the MATCH csv output file specifying the estimated alignment.\n",
    "    \n",
    "    Inputs\n",
    "    infile: filepath to the MATCH csv output file\n",
    "    \n",
    "    Returns a 2xN array indicating the estimated alignment in seconds.\n",
    "    '''\n",
    "    d = pd.read_csv(infile, header=None)\n",
    "    return np.vstack((d.loc[:,1], d.loc[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(scenario_dir, out_dir, cache_dir, hop_sec, oracle = False):\n",
    "    '''\n",
    "    Carries out `online' processing using the MATCH algorithm.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    out_dir: The directory to put results, intermediate files, and logging info\n",
    "    cache_dir: The cache directory\n",
    "    hop_sec: The hop size in sec used in the offline DTW stage\n",
    "    oracle: boolean specifying if oracle information for query ending time should be used\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    \n",
    "    # verify & setup\n",
    "    verify_match_installation()\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "           \n",
    "    # determine the start time of the query in the orchestra recording (ground truth)\n",
    "    orch_start_sec, orch_end_sec = system_utils.get_orchestra_query_boundaries(scenario_dir)\n",
    "    \n",
    "    # infer the start time of the query in the full mix recording (estimated)\n",
    "    wp_BC_frm = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "    wp_BC_frm = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC_frm)) # prepend (0,0) to handle edge cases properly\n",
    "    wp_BC_sec = wp_BC_frm * hop_sec\n",
    "    fullmix_start_sec = np.interp(orch_start_sec, wp_BC_sec[1,:], wp_BC_sec[0,:])    \n",
    "    \n",
    "    # create audio recording of full mix containing the region of interest\n",
    "    fullmix_orig_filepath = f'{scenario_dir}/po.wav'\n",
    "    fullmix_mod_filepath = f'{out_dir}/po_mod.wav'\n",
    "    if oracle:\n",
    "        # use both start and end locations\n",
    "        fullmix_end_sec = np.interp(orch_end_sec, wp_BC_sec[1,:], wp_BC_sec[0,:]) # estimate end time of query in full mix\n",
    "        subprocess.run(['sox', fullmix_orig_filepath, fullmix_mod_filepath, 'rate', '22050', 'channels', '1', 'trim', str(fullmix_start_sec), str(fullmix_end_sec)],\n",
    "                   check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    else:\n",
    "        # only use start location (continue until end of recording)\n",
    "        subprocess.run(['sox', fullmix_orig_filepath, fullmix_mod_filepath, 'rate', '22050', 'channels', '1', 'trim', str(fullmix_start_sec)],\n",
    "                   check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    # run MATCH plugin\n",
    "    piano_filepath = f'{scenario_dir}/p.wav'\n",
    "    match_align_filepath = f'{out_dir}/match_p_po.out'\n",
    "    with open(match_align_filepath, 'w') as f:\n",
    "        subprocess.run(['sonic-annotator', '-d', 'vamp:match-vamp-plugin:match:b_a', '-m', piano_filepath, fullmix_mod_filepath, '-w', 'csv', '--csv-stdout'],\n",
    "                       check=True, stdout=f, stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    # infer piano-orchestra alignment\n",
    "    wp_AB_sec = parse_match_outfile(match_align_filepath) # piano-fullmix alignment\n",
    "\n",
    "    duration = lb.get_duration(path=piano_filepath)\n",
    "    transposed = wp_AB_sec.transpose()\n",
    "    transposed = transposed[transposed[:, 0] < duration].transpose()\n",
    "    transposed[1,:] = transposed[1,:] + fullmix_start_sec # account for offset\n",
    "\n",
    "    wp_AC_sec = align_tools.infer_alignment(transposed, wp_BC_sec) \n",
    "    np.save(f'{out_dir}/hyp.npy', wp_AC_sec)\n",
    "\n",
    "    # save debugging info\n",
    "    np.save(f'{out_dir}/p_po_align.npy', transposed)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp.npy'), f'{indir} is missing the required files, please re run the online processing'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s117'\n",
    "# out_dir = 'experiments/match/s117'\n",
    "# cache_dir = 'experiments/match/cache/beeth1_mov1_O1_PO2'\n",
    "# hop_size = 512\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3], dtype=np.float64)\n",
    "# # offline_processing(scenario_dir, cache_dir, hop_size, steps, weights)\n",
    "\n",
    "# # determine the start time of the query in the orchestra recording (ground truth)\n",
    "# orch_start_sec, orch_end_sec = system_utils.get_orchestra_query_boundaries(scenario_dir)\n",
    "\n",
    "# # infer the start time of the query in the full mix recording (estimated)\n",
    "# wp_BC_frm = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "# wp_BC_frm = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC_frm)) # prepend (0,0) to handle edge cases properly\n",
    "# wp_BC_sec = wp_BC_frm * 0.023219954648526078\n",
    "# fullmix_start_sec = np.interp(orch_start_sec, wp_BC_sec[1,:], wp_BC_sec[0,:])   \n",
    "\n",
    "# # run MATCH plugin\n",
    "# piano_filepath = f'{scenario_dir}/p.wav'\n",
    "# match_align_filepath = f'{out_dir}/match_p_po.out'\n",
    "# fullmix_mod_filepath = f'{out_dir}/po_mod.wav'\n",
    "# with open(match_align_filepath, 'w') as f:\n",
    "#     subprocess.run(['sonic-annotator', '-q', '-d', 'vamp:match-vamp-plugin:match:b_a', '-m', piano_filepath, fullmix_mod_filepath, '-w', 'csv', '--csv-stdout'],\n",
    "#                     check=True, stdout=f, stderr=subprocess.DEVNULL) \n",
    "# # pdata, prate = lb.load(piano_filepath, mono=True, sr=22050)\n",
    "# # fdata, frate = lb.load(fullmix_mod_filepath, mono=True, sr=22050)\n",
    "# # assert prate == frate, 'Piano and full mix sample rates do not match'\n",
    "# # vamp.list_plugins()\n",
    "# # vamp.get_outputs_of('match-vamp-plugin:match')\n",
    "# # vamp_result = vamp.collect(sonify_tools.mix_separate_channels(pdata, fdata, pad=True).transpose(), prate, 'match-vamp-plugin:match', output='b_a', parameters={'smooth': 1, 'usechroma': 1, 'metric': 2, 'noise': 1})\n",
    "# # wp_AB_sec = np.array([[float(item['timestamp']), float(item['values'][0])] for item in vamp_result['list']]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d07e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wp_AB_sec = np.vstack(([i['timestamp'] for i in vamp_result['list']], [i['values'][0] for i in vamp_result['list']]))\n",
    "# infer piano-orchestra alignment\n",
    "# wp_AB_sec = parse_match_outfile(match_align_filepath) # piano-fullmix alignment\n",
    "# # wp_AB_sec[1,:] = wp_AB_sec[1,:] + fullmix_start_sec # account for offset\n",
    "\n",
    "# # crop alignment to the duration of the piano recording\n",
    "# duration = lb.get_duration(filename=piano_filepath)\n",
    "# transposed = wp_AB_sec.transpose()\n",
    "# transposed = transposed[transposed[:, 0] < duration].transpose()\n",
    "# transposed[1,:] = transposed[1,:] + fullmix_start_sec # account for offset\n",
    "\n",
    "\n",
    "# wp_AC_sec = align_tools.infer_alignment(transposed, wp_BC_sec) \n",
    "# np.save(f'{out_dir}/hyp.npy', wp_AC_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(' '.join(['sonic-annotator', '-d', 'vamp:match-vamp-plugin:match:b_a', '-m', piano_filepath, fullmix_mod_filepath, '-w', 'csv', '--csv-stdout']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdata, prate = lb.load(piano_filepath, mono=True, sr=22050)\n",
    "# fdata, frate = lb.load(fullmix_mod_filepath, mono=True, sr=22050)\n",
    "# assert prate == frate, 'Piano and full mix sample rates do not match'\n",
    "# # vamp.list_plugins()\n",
    "# # vamp.get_outputs_of('match-vamp-plugin:match')\n",
    "# vamp_result = vamp.collect(sonify_tools.mix_separate_channels(pdata, fdata).transpose(), prate, 'match-vamp-plugin:match', output='b_a', parameters={'smooth': 1, 'metric': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5af517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# alignment = np.array([[float(item['timestamp']), float(item['values'][0])] for item in vamp_result['list']]).transpose()\n",
    "\n",
    "# plt.plot(alignment[1], alignment[0])\n",
    "# plt.xlabel('Source Time')\n",
    "# plt.ylabel('Aligned Time')\n",
    "# plt.ylim(ymin=0)\n",
    "# plt.xlim(xmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea815525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
