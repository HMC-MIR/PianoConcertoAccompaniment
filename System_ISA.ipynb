{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# ISA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook provides wrapper functions for calling the [ISA (Iterative Subtractive Alignment) algorithm](https://archives.ismir.net/ismir2021/paper/000101.pdf).  Running this algorithm requires installing some other software, which is described below.  This notebook implements the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610e1142",
   "metadata": {},
   "source": [
    "In the offline processing stage, three things are computed and stored in the `cache/` folder:\n",
    "- chroma features for the orchestra recording\n",
    "- chroma features for the full mix recording (minus the aligned chroma features for the piano)\n",
    "- predicted DTW alignment between the orchestra and full mix recordings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from System_OfflineDTW.ipynb\n",
      "importing Jupyter notebook from align_tools.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import System_OfflineDTW\n",
    "import system_utils\n",
    "import align_tools\n",
    "import sonify_tools\n",
    "import os\n",
    "import os.path\n",
    "import subprocess\n",
    "import librosa as lb\n",
    "import vamp\n",
    "from shutil import which\n",
    "from hmc_mir.align import isa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d510a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_five_second_segments(piano_cqt):\n",
    "    n = piano_cqt.shape[1]\n",
    "    return [[i, min(i+215, n)] for i in range(0, n, 215)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length, alg='cqt'):\n",
    "    '''\n",
    "    Carries out the same offline processing steps as the simple offline DTW system.\n",
    "    \n",
    "    Args:\n",
    "        scenario_dir: The scenario directory to process\n",
    "        cache_dir: The location of the cache directory\n",
    "        hop_length: The hop length in samples used when computing chroma features\n",
    "        alg: The chroma feature algorithm to use. Must be one of 'cqt', 'bcqt', or 'chroma'.\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    # setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    if os.path.exists(cache_dir):\n",
    "        # print(f'{cache_dir} has already been processed.  Skipping.')\n",
    "        pass\n",
    "    else:\n",
    "        # setup\n",
    "        os.makedirs(cache_dir)\n",
    "\n",
    "\n",
    "\n",
    "        orch_start_sec, orch_end_sec = system_utils.get_orchestra_start_end_times(scenario_dir)\n",
    "\n",
    "        o_file = f'{scenario_dir}/o.wav'\n",
    "        y_o, sr = lb.core.load(o_file)\n",
    "        y_o = y_o[int(orch_start_sec*sr):int(orch_end_sec*sr)]\n",
    "        F_o = isa.calculate_cqt(y_o, sr, hop_length)\n",
    "        segments_o = split_into_five_second_segments(F_o)\n",
    "\n",
    "        po_file = f'{scenario_dir}/po.wav'\n",
    "        y_po, sr = lb.core.load(po_file)\n",
    "        F_po = isa.calculate_cqt(y_po, sr, hop_length)\n",
    "\n",
    "        if alg == 'cqt':\n",
    "            F_po_subtracted, wp = isa.isa_cqt(F_o, F_po, segments_o)\n",
    "        elif alg == 'bcqt':\n",
    "            F_po_subtracted, wp = isa.isa_bcqt(F_o, F_po, segments_o)\n",
    "        elif alg == 'chroma':\n",
    "            F_po_subtracted, wp = isa.isa_chroma(F_o, F_po, segments_o)\n",
    "        else:\n",
    "            raise ValueError(f'alg must be one of cqt, bcqt, or chroma.  Received {alg}')\n",
    "\n",
    "        orch_start_frm = int(np.round(orch_start_sec * sr / hop_length))\n",
    "        orch_end_frm = int(np.round(orch_end_sec * sr / hop_length)) + 1\n",
    "        wp[0,:] = wp[0,:] + orch_start_frm # account for offset\n",
    "\n",
    "        np.save(f'{cache_dir}/po_subtracted_cqt.npy', F_po_subtracted)\n",
    "        np.save(f'{cache_dir}/o_po_align.npy', wp)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75fcf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/po_subtracted_cqt.npy'), f'missing {indir}/po_subtracted_cqt.npy'\n",
    "    assert os.path.exists(f'{indir}/o_po_align.npy'), f'missing {indir}/o_po_align.npy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "## Online Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d865c60",
   "metadata": {},
   "source": [
    "### Wrapper Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f22bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(scenario_dir, out_dir, cache_dir, hop_length, alg='cqt'):\n",
    "    '''\n",
    "    Carries out `online' processing using the ISA algorithm.\n",
    "    \n",
    "    Args:\n",
    "        scenario_dir: The scenario directory to process\n",
    "        out_dir: The directory to put results, intermediate files, and logging info\n",
    "        cache_dir: The cache directory\n",
    "        hop_length: The hop length in samples used when computing cqt features\n",
    "        alg: The chroma feature algorithm to use. Must be one of 'cqt', 'bcqt', or 'chroma'.\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    \n",
    "    # verify & setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "    orch_start_sec, orch_end_sec = system_utils.get_orchestra_query_boundaries(scenario_dir)\n",
    "\n",
    "    # compute features\n",
    "    p_file = f'{scenario_dir}/p.wav'\n",
    "    y, sr = lb.core.load(p_file)\n",
    "    hop_sec = hop_length / sr\n",
    "\n",
    "    wp_BC = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "    wp_BC = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC)) # prepend (0,0) to handle edge cases properly\n",
    "    fullmix_start_frm = int(np.interp(orch_start_sec*hop_sec, wp_BC[1,:], wp_BC[0,:])) # estimate end time of query in full mix\n",
    "\n",
    "    F_p = isa.calculate_cqt(y, sr, hop_length)  # piano features\n",
    "    segments_p = split_into_five_second_segments(F_p)\n",
    "    F_po_subtracted = np.load(f'{cache_dir}/po_subtracted_cqt.npy') # full mix features\n",
    "    F_po_subtracted = F_po_subtracted[:,fullmix_start_frm:] # truncate to start of query\n",
    "\n",
    "    if alg == 'cqt':\n",
    "        F_po_empty, wp_AB = isa.isa_cqt(F_p, F_po_subtracted, segments_p)\n",
    "    elif alg == 'bcqt':\n",
    "        F_po_empty, wp_AB = isa.isa_bcqt(F_p, F_po_subtracted, segments_p)\n",
    "    elif alg == 'chroma':\n",
    "        F_po_empty, wp_AB = isa.isa_chroma(F_p, F_po_subtracted, segments_p)\n",
    "    else:\n",
    "        raise ValueError(f'alg must be one of cqt, bcqt, or chroma.  Received {alg}')\n",
    "\n",
    "    wp_AB[1,:] = wp_AB[1,:] + fullmix_start_frm # account for offset\n",
    "    \n",
    "    # infer piano-orchestra alignment\n",
    "    wp_AC = align_tools.infer_alignment(wp_AB, wp_BC, frames=True)\n",
    "    \n",
    "    np.save(f'{out_dir}/hyp.npy', wp_AC*hop_sec)\n",
    "    np.save(f'{out_dir}/p_po_align.npy', wp_AB)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b46c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp.npy'), f'{indir} is missing the required files, please re run the online processing'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51aef5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s2'\n",
    "# out_dir = 'experiments/ISA_CQT/s2'\n",
    "# cache_dir = 'experiments/ISA_CQT/cache/rach2_mov1_O1_PO1'\n",
    "# hop_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d17349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orch_start_sec, orch_end_sec = system_utils.get_orchestra_start_end_times(scenario_dir)\n",
    "\n",
    "# o_file = f'{scenario_dir}/o.wav'\n",
    "# y_o, sr = lb.core.load(o_file)\n",
    "# y_o = y_o[int(orch_start_sec*sr):int(orch_end_sec*sr)]\n",
    "# F_o = isa.calculate_cqt(y_o, sr, hop_length)\n",
    "# segments_o = split_into_five_second_segments(F_o)\n",
    "\n",
    "# po_file = f'{scenario_dir}/po.wav'\n",
    "# y_po, sr = lb.core.load(po_file)\n",
    "# F_po = isa.calculate_cqt(y_po, sr, hop_length)\n",
    "\n",
    "# F_po_subtracted, wp = isa.isa_chroma(F_o, F_po, segments_o)\n",
    "\n",
    "# orch_start_frm = int(np.round(orch_start_sec * sr / hop_length))\n",
    "# orch_end_frm = int(np.round(orch_end_sec * sr / hop_length + 1))\n",
    "# wp[0,:] = wp[0,:] + orch_start_frm  # account for offset\n",
    "\n",
    "# np.save(f'{cache_dir}/po_subtracted_cqt.npy', F_po_subtracted)\n",
    "# np.save(f'{cache_dir}/o_po_align.npy', wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac9c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtw_wp = np.load('experiments/offlineDTW/cache/rach2_mov1_O1_PO1/o_po_align.npy')\n",
    "# # dtw_wp = np.load('experiments/offlineDTW/s2/p_po_align.npy')\n",
    "\n",
    "# wp_scaled = wp\n",
    "\n",
    "# plt.plot(dtw_wp[0], dtw_wp[1], 'o', label=\"dtw\")\n",
    "# plt.plot(wp_scaled[0], wp_scaled[1], 'o', label=\"isa\")\n",
    "# plt.ylim(ymin=0)\n",
    "# plt.xlim(xmin=0)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "985b3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_file = f'{scenario_dir}/p.wav'\n",
    "# y, sr = lb.core.load(p_file)\n",
    "\n",
    "# hop_sec = hop_length / sr\n",
    "# orch_start_sec, _ = system_utils.get_orchestra_query_boundaries(scenario_dir)\n",
    "# orch_start_frm = orch_start_sec / hop_sec  # keep max precision, don't round\n",
    "\n",
    "# # infer the start time of the query in the full mix recording (estimated)\n",
    "# wp_BC = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "# wp_BC = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC)) # prepend (0,0) to handle edge cases properly\n",
    "# fullmix_start_frm = int(np.round(np.interp(orch_start_frm, wp_BC[1,:], wp_BC[0,:])))\n",
    "\n",
    "# F_p = isa.calculate_cqt(y, sr, hop_length)  # piano features\n",
    "# F_po = np.load(f'{cache_dir}/po_subtracted_cqt.npy') # full mix features\n",
    "# F_po = F_po[:,fullmix_start_frm:] # truncate to start of query\n",
    "# segments_p = split_into_five_second_segments(F_p)\n",
    "\n",
    "# F_po_subtracted, wp_AB = isa.isa_chroma(F_p, F_po, segments_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1196745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wp_AB = np.load('experiments/offlineDTW/s2/p_po_align.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3fe4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # infer piano-orchestra alignment\n",
    "# wp_AB_ = wp_AB.copy()\n",
    "# wp_AB_[1,:] = wp_AB_[1,:] + fullmix_start_frm\n",
    "# wp_AC = align_tools.infer_alignment(wp_AB_, wp_BC, frames=True)\n",
    "# np.save(f'{out_dir}/hyp.npy', wp_AC*hop_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6473c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_utils.get_orchestra_query_boundaries(scenario_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a5af517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# alignment1 = wp_AB_\n",
    "# alignment2 = wp_BC\n",
    "# alignment3 = wp_AC\n",
    "\n",
    "# plt.plot(alignment1[1], alignment1[0], label='AB')\n",
    "# plt.plot(alignment2[1], alignment2[0], label='BC')\n",
    "# plt.plot(alignment3[1], alignment3[0], label='AC')\n",
    "# plt.xlabel('Source Time')\n",
    "# plt.ylabel('Aligned Time')\n",
    "# plt.ylim(ymin=0)\n",
    "# plt.xlim(xmin=0)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
