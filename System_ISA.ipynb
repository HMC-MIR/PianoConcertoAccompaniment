{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# ISA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook provides wrapper functions for calling the [ISA (Iterative Subtractive Alignment) algorithm](https://archives.ismir.net/ismir2021/paper/000101.pdf).  Running this algorithm requires installing some other software, which is described below.  This notebook implements the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610e1142",
   "metadata": {},
   "source": [
    "In the offline processing stage, three things are computed and stored in the `cache/` folder:\n",
    "- CQT features for the orchestra recording\n",
    "- CQT features for the full mix recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import System_OfflineDTW\n",
    "import system_utils\n",
    "import align_tools\n",
    "import sonify_tools\n",
    "import os\n",
    "import os.path\n",
    "import subprocess\n",
    "import librosa as lb\n",
    "from shutil import which\n",
    "from hmc_mir.align import isa, dtw\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit, prange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d510a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_five_second_segments(piano_cqt):\n",
    "    n = piano_cqt.shape[1]\n",
    "    return [[i, min(i+215, n)] for i in range(0, n, 215)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length, alg='cqt'):\n",
    "    '''\n",
    "    Carries out the same offline processing steps as the simple offline DTW system.\n",
    "    \n",
    "    Args:\n",
    "        scenario_dir: The scenario directory to process\n",
    "        cache_dir: The location of the cache directory\n",
    "        hop_length: The hop length in samples used when computing chroma features\n",
    "        alg: The chroma feature algorithm to use. Must be one of 'cqt', 'bcqt', or 'chroma'.\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    # setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    if os.path.exists(cache_dir):\n",
    "        # print(f'{cache_dir} has already been processed.  Skipping.')\n",
    "        pass\n",
    "    else:\n",
    "        # setup\n",
    "        os.makedirs(cache_dir)\n",
    "\n",
    "        o_file = f'{scenario_dir}/o.wav'\n",
    "        y_o, sr = lb.core.load(o_file)\n",
    "        F_o = isa.calculate_cqt(y_o, sr, hop_length)\n",
    "\n",
    "        po_file = f'{scenario_dir}/po.wav'\n",
    "        y_po, sr = lb.core.load(po_file)\n",
    "        F_po = isa.calculate_cqt(y_po, sr, hop_length)\n",
    "\n",
    "        np.save(f'{cache_dir}/o_cqt.npy', F_o)\n",
    "        np.save(f'{cache_dir}/po_cqt.npy', F_po)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fcf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/o_cqt.npy'), f'o_cqt.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/po_cqt.npy'), f'po_cqt.npy missing from {indir}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "## Online Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ffae4-4fcb-428f-9c94-ea1b84f9ccd1",
   "metadata": {},
   "source": [
    "In the online processing stage, the following steps are done:\n",
    "- estimate the P-PO alignment using standard subsequence DTW with chroma features\n",
    "- perform spectral subtraction of P from PO, which produces an estimate of the O CQT features in the PO recording\n",
    "- estimate the PO_O_est - O alignment using subsequence DTW with chroma features\n",
    "- infer the P-O alignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d865c60",
   "metadata": {},
   "source": [
    "### Wrapper Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(scenario_dir, out_dir, cache_dir, hop_length, alg='cqt'):\n",
    "    '''\n",
    "    Carries out `online' processing using the ISA algorithm.\n",
    "    \n",
    "    Args:\n",
    "        scenario_dir: The scenario directory to process\n",
    "        out_dir: The directory to put results, intermediate files, and logging info\n",
    "        cache_dir: The cache directory\n",
    "        hop_length: The hop length in samples used when computing cqt features\n",
    "        alg: The chroma feature algorithm to use. Must be one of 'cqt', 'bcqt', or 'chroma'.\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    timestamps = []\n",
    "    \n",
    "    # verify & setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "    # compute features\n",
    "    p_file = f'{scenario_dir}/p.wav'\n",
    "    y, sr = lb.core.load(p_file)\n",
    "    hop_sec = hop_length / sr\n",
    "    F_p = isa.calculate_cqt(y, sr, hop_length)  # piano CQT\n",
    "    F_po = np.load(f'{cache_dir}/po_cqt.npy') # full mix CQT\n",
    "    F_o = np.load(f'{cache_dir}/o_cqt.npy') # orchestra CQT\n",
    "\n",
    "    # preliminary P-PO alignment (just to select the appropriate section of PO to perform ISA)\n",
    "    timestamps.append(time.time())\n",
    "    buffer = int(1/hop_sec) # include a buffer of 1 sec on either end of estimated alignment\n",
    "    C = align_tools.cosine_dist(isa.cqt_to_chroma(F_p), isa.cqt_to_chroma(F_po))\n",
    "    D, B, p_po_path = dtw.dtw(C, np.array([[1,1],[1,2],[2,1]]),[1,1,2], True)\n",
    "    F_po_match = F_po[:, max(p_po_path[1,0]-buffer, 0):min(p_po_path[1,-1]+buffer, F_po.shape[1])]\n",
    "    po_offset = max(p_po_path[1,0]-buffer, 0)\n",
    "\n",
    "    timestamps.append(time.time())\n",
    "    segments_p = split_into_five_second_segments(F_p)\n",
    "\n",
    "    if alg == 'cqt':\n",
    "        F_po_o_est, wp_AB = isa.isa_cqt(F_p, F_po_match, segments_p)\n",
    "    elif alg == 'bcqt':\n",
    "        F_po_o_est, wp_AB = isa.isa_bcqt(F_p, F_po_match, segments_p)\n",
    "    elif alg == 'chroma':\n",
    "        F_po_o_est, wp_AB = isa.isa_chroma(F_p, F_po_match, segments_p)\n",
    "    else:\n",
    "        raise ValueError(f'alg must be one of cqt, bcqt, or chroma.  Received {alg}')\n",
    "\n",
    "    wp_AB[1,:] = wp_AB[1,:] + po_offset # account for offset in P-PO alignment\n",
    "\n",
    "    timestamps.append(time.time())\n",
    "    C = align_tools.cosine_dist(isa.cqt_to_chroma(F_po_o_est), isa.cqt_to_chroma(F_o))\n",
    "    D, B, po_o_path = dtw.dtw(C, np.array([[1,1],[1,2],[2,1]]),[1,1,2], True)\n",
    "    po_o_path[0,:] += po_offset # account for offset in PO-O alignment\n",
    "    timestamps.append(time.time())\n",
    "    \n",
    "    # infer piano-orchestra alignment\n",
    "    wp_AC = align_tools.infer_alignment(wp_AB, po_o_path, frames=True) # inferred P-O alignment\n",
    "    timestamps.append(time.time())\n",
    "    \n",
    "    np.save(f'{out_dir}/hyp.npy', wp_AC*hop_sec)\n",
    "    np.save(f'{out_dir}/p_po_align.npy', wp_AB)\n",
    "    np.save(f'{out_dir}/runtime.npy', np.array(timestamps))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp.npy'), f'{indir} is missing the required files, please re run the online processing'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eca96c-6434-43fb-bd9c-d386ab185703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s2'\n",
    "# out_dir = 'experiments/test/s2'\n",
    "# cache_dir = 'experiments/test/cache'\n",
    "# hop_size = 512\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3])\n",
    "# offline_processing(scenario_dir, cache_dir, hop_size, steps, weights)\n",
    "# online_processing(scenario_dir, out_dir, cache_dir, hop_size, steps, weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
