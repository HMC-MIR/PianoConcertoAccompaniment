{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49c20f2f",
   "metadata": {},
   "source": [
    "# Time Scale Modification Tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28fd5d9e",
   "metadata": {},
   "source": [
    "This notebook implements the time scale modification algorithms described in \"[A Review of Time-Scale Modification of Music Signals](https://www.mdpi.com/2076-3417/6/2/57)\" by Driedger and Mueller.  We also implement variants of these algorithms that time scale modify a recording according to a predicted alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699a752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "from scipy.signal import medfilt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0444155",
   "metadata": {},
   "source": [
    "## Implement Time Scale Modification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ba67066",
   "metadata": {},
   "source": [
    "The functions below implement a time scale modification algorithm in which:\n",
    "- the input signal is separated in harmonic and percussive components,\n",
    "- the harmonic component is time-scale modified using a phase vocoder, and\n",
    "- the percussive component is time-scaled modified using an overlap-add method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c889bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_percussive_separation(x, sr=22050, fft_size = 2048, hop_length=512, lh=6, lp=6):\n",
    "    '''\n",
    "    Performs harmonic-percussive separation on a given audio sample.\n",
    "    \n",
    "    Inputs\n",
    "    x: the input audio waveform\n",
    "    sr: sample rate of the audio data\n",
    "    fft_size: specifies the FFT size to use in computing an STFT\n",
    "    hop_length: specifies the hop length in samples to use in computing an STFT\n",
    "    lh: the harmonic spectrotemporal median filter will be of size (1, 2*lh+1)\n",
    "    lp: the percussive spectrotemporal median filter will be of size (2*lp+1, 1)\n",
    "    \n",
    "    Outputs\n",
    "    xh: audio waveform of the estimated harmonic component\n",
    "    xp: audio waveform of the estimated percussive component\n",
    "    Xh: an STFT of the input signal with percussive components masked out\n",
    "    Xp: an STFT of the input signal with harmonic components masked out\n",
    "    '''\n",
    "    \n",
    "    window = hann_window(fft_size)\n",
    "    X = lb.core.stft(x, n_fft=fft_size, hop_length=512, window=window, center=False)\n",
    "    Y = np.abs(X)\n",
    "    Yh = medfilt(Y, (1, 2*lh+1))\n",
    "    Yp = medfilt(Y, (2*lp+1, 1))\n",
    "    Mh = (Yh > Yp)\n",
    "    Mp = np.logical_not(Mh)\n",
    "    Xh = X * Mh\n",
    "    Xp = X * Mp\n",
    "    xh = invert_stft(Xh, hop_length, window)\n",
    "    xp = invert_stft(Xp, hop_length, window)\n",
    "    \n",
    "    return xh, xp, Xh, Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550573ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hann_window(L):\n",
    "    '''\n",
    "    Returns a Hann window of a specified length.\n",
    "    \n",
    "    Inputs\n",
    "    L: length of window to return\n",
    "    '''\n",
    "    w = .5 * (1 - np.cos(2*np.pi * np.arange(L)/ L))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cdf744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_stft(S, hop_length, window):\n",
    "    '''\n",
    "    Reconstruct a signal from a modified STFT matrix.\n",
    "    \n",
    "    Inputs\n",
    "    S: modified STFT matrix\n",
    "    hop_length: the synthesis hop size in samples\n",
    "    window: an array specifying the window used for FFT analysis\n",
    "    \n",
    "    Returns a time-domain signal y whose STFT is closest to S in squared error distance.\n",
    "    '''\n",
    "    \n",
    "    L = len(window)\n",
    "    \n",
    "    # construct full stft matrix\n",
    "    fft_size = (S.shape[0] - 1) * 2\n",
    "    Sfull = np.zeros((fft_size, S.shape[1]), dtype=np.complex64)\n",
    "    Sfull[0:S.shape[0],:] = S\n",
    "    Sfull[S.shape[0]:,:] = np.conj(np.flipud(S[1:fft_size//2,:]))\n",
    "    \n",
    "    # compute inverse FFTs\n",
    "    frames = np.zeros_like(Sfull)\n",
    "    for i in range(frames.shape[1]):\n",
    "        frames[:,i] = np.fft.ifft(Sfull[:,i])\n",
    "    frames = np.real(frames) # remove imaginary components due to numerical roundoff\n",
    "    \n",
    "    # synthesis frames\n",
    "    num = window.reshape((-1,1))\n",
    "    den = calc_sum_squared_window(window, hop_length)\n",
    "    #den = np.square(window) + np.square(np.roll(window, hop_length))\n",
    "    frames = frames * window.reshape((-1,1)) / den.reshape((-1,1))\n",
    "    #frames = frames * window.reshape((-1,1))\n",
    "    \n",
    "    # reconstruction\n",
    "    y = np.zeros(hop_length*(frames.shape[1]-1) + L)\n",
    "    for i in range(frames.shape[1]):\n",
    "        offset = i * hop_length\n",
    "        y[offset:offset+L] += frames[:,i]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa35f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sum_squared_window(window, hop_length):\n",
    "    '''\n",
    "    Calculates the denominator term for computing synthesis frames.\n",
    "    \n",
    "    Inputs\n",
    "    window: array specifying the window used in FFT analysis\n",
    "    hop_length: the synthesis hop size in samples\n",
    "    \n",
    "    Returns an array specifying the normalization factor.\n",
    "    '''\n",
    "    assert (len(window) % hop_length == 0), \"Hop length does not divide the window evenly.\"\n",
    "    \n",
    "    numShifts = len(window) // hop_length\n",
    "    den = np.zeros_like(window)\n",
    "    for i in range(numShifts):\n",
    "        den += np.roll(np.square(window), i*hop_length)\n",
    "        \n",
    "    return den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c436a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsm_phase_vocoder(x, alpha = 1.0, L = 2048, sr = 22050):\n",
    "    '''\n",
    "    Time stretches the input signal using the phase vocoder method.  Uses a synthesis hop size that is \n",
    "    one-fourth the value of L.  Note that this implementation allows for a non-integer analysis hop size\n",
    "    (in samples), which ensures that the time-scale modification factor is exactly as specified.\n",
    "    \n",
    "    Inputs\n",
    "    x: the input signal\n",
    "    alpha: the time stretch factor, which is defined as the ratio of the synthesis hop size to the analysis hop size\n",
    "    L: the length of each analysis frame in samples\n",
    "    sr: sampling rate\n",
    "    \n",
    "    Returns the time-stretched signal y.\n",
    "    '''\n",
    "    assert(L % 4 == 0), \"Frame length must be divisible by four.\"\n",
    "    Hs = L // 4\n",
    "    \n",
    "    # compute STFT\n",
    "    Ha = Hs/alpha # allow non-integer values\n",
    "    window = hann_window(L)\n",
    "    X, analysis_frame_offsets = my_stft(x, L, Ha, window) # custom implementation to handle non-integer hop size\n",
    "    \n",
    "    # compute modified STFT\n",
    "    w_if = estimateIF_var(X, sr, analysis_frame_offsets/sr) # custom implementation to handle non-constant frame locations\n",
    "    phase_mod = np.zeros(X.shape)\n",
    "    phase_mod[:,0] = np.angle(X[:,0])\n",
    "    for i in range(1, phase_mod.shape[1]):\n",
    "        phase_mod[:,i] = phase_mod[:,i-1] + w_if[:,i-1] * Hs / sr\n",
    "    Xmod = np.abs(X) * np.exp(1j * phase_mod)\n",
    "    \n",
    "    # signal reconstruction\n",
    "    y = invert_stft(Xmod, Hs, window)\n",
    "    #y = lb.core.istft(Xmod, hop_length=Hs, center=False)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e5d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_stft(x, N, hop_length, window):\n",
    "    '''\n",
    "    A custom implementation of the STFT that allows for non-integer hop lengths (in samples).\n",
    "    \n",
    "    Inputs\n",
    "    x: the input audio waveform\n",
    "    N: the FFT size\n",
    "    hop_length: the hop size specified in samples, can be a non-integer\n",
    "    window: the window to apply to the analysis frames\n",
    "    \n",
    "    Outputs\n",
    "    X: the computed STFT matrix\n",
    "    frame_offsets: a list specifying the offsets (in samples) of each analysis frame\n",
    "    '''\n",
    "    \n",
    "    assert len(window) == N\n",
    "    \n",
    "    # get analysis frames\n",
    "    numFrames = int((len(x) - N) // hop_length) + 1\n",
    "    analysisFrames = np.zeros((numFrames, N))\n",
    "    frame_offsets = np.rint(np.arange(numFrames) * hop_length).astype(int)\n",
    "    for i, offset in enumerate(frame_offsets):\n",
    "        analysisFrames[i,:] = x[offset: offset + N]\n",
    "\n",
    "    # compute STFT\n",
    "    analysisFrames = analysisFrames * window.reshape((1,-1))\n",
    "    Xfull = np.fft.fft(analysisFrames, axis=1)\n",
    "    halfLen = N//2 + 1\n",
    "    X = Xfull[:,0:halfLen].T\n",
    "\n",
    "    return X, frame_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27e496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateIF(S, sr, hop_samples):\n",
    "    '''\n",
    "    Estimates the instantaneous frequencies in a STFT matrix.\n",
    "    \n",
    "    Note: This function is not actually used in our custom implementation of the phase vocoder -- \n",
    "    it is included here as a contrast to estimateIF_var() below.\n",
    "    \n",
    "    Inputs\n",
    "    S: the STFT matrix, should only contain the lower half of the frequency bins\n",
    "    sr: sampling rate\n",
    "    hop_samples: the hop size of the STFT analysis in samples\n",
    "    \n",
    "    Returns a matrix containing the estimated instantaneous frequency at each time-frequency bin.\n",
    "    This matrix should contain one less column than S.\n",
    "    '''\n",
    "    hop_sec = hop_samples / sr\n",
    "    fft_size = (S.shape[0] - 1) * 2\n",
    "    w_nom = np.arange(S.shape[0]) * sr / fft_size * 2 * np.pi\n",
    "    w_nom = w_nom.reshape((-1,1))    \n",
    "    unwrapped = np.angle(S[:,1:]) - np.angle(S[:,0:-1]) - w_nom * hop_sec\n",
    "    wrapped = (unwrapped + np.pi) % (2 * np.pi) - np.pi\n",
    "    w_if = w_nom + wrapped / hop_sec\n",
    "    return w_if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41d64123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsm_overlap_add(x, alpha = 1.0, L = 220):\n",
    "    '''\n",
    "    Time stretches the input signal using the overlap-add method.  Uses a synthesis hop size that is half the\n",
    "    value of L.  Note that this implementation allows for a non-integer analysis hop size (in samples), which\n",
    "    ensures that the time-scale modification factor is exactly as specified.\n",
    "    \n",
    "    Inputs\n",
    "    x: the input signal\n",
    "    alpha: the time stretch factor, which is defined as the ratio of the synthesis hop size to the analysis hop size\n",
    "    L: the length of each analysis frame in samples\n",
    "    \n",
    "    Returns the time-stretched signal y.\n",
    "    '''\n",
    "    assert(L % 2 == 0), \"Frame length must be even.\"\n",
    "    Hs = L // 2\n",
    "    \n",
    "    # compute analysis frames\n",
    "    Ha = Hs/alpha # allow non-integer analysis hop size\n",
    "    numFrames = int((len(x) - L) // Ha) + 1\n",
    "    analysisFrames = np.zeros((L, numFrames))\n",
    "    for i in range(numFrames):\n",
    "        offset = int(np.round(i * Ha))\n",
    "        analysisFrames[:, i] = x[offset: offset + L]\n",
    "    \n",
    "    # reconstruction\n",
    "    synthesisFrames = analysisFrames * hann_window(L).reshape((-1,1)) # use broadcasting\n",
    "    y = np.zeros(Hs * (numFrames-1) + L)\n",
    "    for i in range(numFrames):\n",
    "        offset = i * Hs\n",
    "        y[offset:offset+L] += synthesisFrames[:,i]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f46a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_recordings(x1, x2):\n",
    "    '''\n",
    "    Mixes two audio waveforms together.\n",
    "    \n",
    "    Inputs\n",
    "    x1: first audio waveform\n",
    "    x2: second audio waveform\n",
    "    \n",
    "    Returns an audio waveform that is an average of the two waveforms.  \n",
    "    The length of the returned waveform is the minimum of the two lengths.\n",
    "    '''\n",
    "    min_length = min(len(x1), len(x2))\n",
    "    y = .5 * (x1[0:min_length] + x2[0:min_length])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a0791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsm_hybrid(x, alpha=1.0, sr=22050):\n",
    "    '''\n",
    "    Time stretches the input signal using a hybrid method that combines overlap-add and phase vocoding.\n",
    "    \n",
    "    Inputs\n",
    "    x: the input signal\n",
    "    alpha: the time stretch factor, which is defined as the ratio of the synthesis hop size to the analysis hop size\n",
    "    sr: sampling rate\n",
    "    \n",
    "    Returns the time-stretched signal y.\n",
    "    '''\n",
    "    \n",
    "    xh, xp, _, _ = harmonic_percussive_separation(x)\n",
    "    xh_stretched = tsm_phase_vocoder(xh, alpha)\n",
    "    xp_stretched = tsm_overlap_add(xp, alpha)\n",
    "    y = mix_recordings(xh_stretched, xp_stretched)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fb1ce0c",
   "metadata": {},
   "source": [
    "## Implement Alignment-Based TSM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0774d4d",
   "metadata": {},
   "source": [
    "The functions below implement a time-scale modification algorithm in which the time-stretch factor can be specified at specific instants in time (rather than using a single global time-stretch factor).  This allows us to time-stretch a recording according to a desired alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4cac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsmvar_hybrid(x, alignment, sr=22050):\n",
    "    '''\n",
    "    Time stretches the input signal using a hybrid method that combines overlap-add and phase vocoding.\n",
    "    The time stretch factor is specified at each time instant by the provided alignment.\n",
    "    \n",
    "    Inputs\n",
    "    x: the input signal\n",
    "    alignment: a 2xN matrix specifying the desired alignment in seconds.  The first row indicates the timestamp\n",
    "        in the input signal, and the last row indicates where in the output signal the instant should occur.\n",
    "    sr: sampling rate\n",
    "    \n",
    "    Returns the variable time-stretched signal y.\n",
    "    '''\n",
    "    xh, xp, _, _ = harmonic_percussive_separation(x)\n",
    "    xh_stretched = tsmvar_phase_vocoder(xh, alignment)\n",
    "    xp_stretched = tsmvar_overlap_add(xp, alignment)\n",
    "    y = mix_recordings(xh_stretched, xp_stretched)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20843016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsmvar_overlap_add(x, alignment, L = 220, fs = 22050):\n",
    "    '''\n",
    "    Time stretches the input signal using the overlap-add method according to a given alignment.\n",
    "    Uses a synthesis hop size that is half the value of L.\n",
    "    \n",
    "    Inputs\n",
    "    x: the input signal (orchestra only)\n",
    "    alignment: a 2xN matrix specifying the desired alignment in seconds.  The first row indicates the timestamp\n",
    "        in the input signal, and the last row indicates where in the output signal the instant should occur.\n",
    "    L: the length of each analysis frame in samples\n",
    "    fs: sample rate of input signal\n",
    "    \n",
    "    Returns the variable time-stretched signal y.\n",
    "    '''\n",
    "    assert(L % 2 == 0), \"Frame length must be even.\"\n",
    "    Hs = L // 2\n",
    "\n",
    "    # determine interpolation points\n",
    "    target_dur = alignment[1,-1] # in sec\n",
    "    target_start = alignment[1,0] # if a subsequence alignment, output will be zero until target_start (in sec)\n",
    "    numFrames = int((target_dur * fs - L) // Hs) + 1\n",
    "    analysisFrames = np.zeros((L, numFrames))\n",
    "    interp_pts = np.interp(np.arange(numFrames)*Hs/fs, alignment[1,:], alignment[0,:]) # left edge of analysis windows\n",
    "    \n",
    "    # compute analysis frames    \n",
    "    for i in range(numFrames):\n",
    "        if i*Hs/fs >= target_start:\n",
    "            offset = int(np.round(interp_pts[i] * fs))\n",
    "            offset = min(offset, len(x) - L)\n",
    "            analysisFrames[:, i] = x[offset: offset + L]\n",
    "\n",
    "    # reconstruction\n",
    "    synthesisFrames = analysisFrames * hann_window(L).reshape((-1,1)) # use broadcasting\n",
    "    y = np.zeros(Hs * (numFrames-1) + L)\n",
    "    for i in range(numFrames):\n",
    "        offset = i * Hs\n",
    "        y[offset:offset+L] += synthesisFrames[:,i]\n",
    "            \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79c74420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsmvar_phase_vocoder(x, alignment, L = 2048, fs = 22050):\n",
    "    '''\n",
    "    Time stretches the input signal using a phase vocoder according to a given alignment.  \n",
    "    Uses a synthesis hop size that is one-fourth the value of L.\n",
    "    \n",
    "    Inputs\n",
    "    x: the input signal\n",
    "    alignment: a 2xN matrix specifying the desired alignment in seconds.  The first row indicates the timestamp\n",
    "        in the input signal, and the last row indicates where in the output signal the instant should occur.\n",
    "    L: the length of each analysis frame in samples\n",
    "    fs: sampling rate\n",
    "    \n",
    "    Returns the variable time-stretched signal y.\n",
    "    '''\n",
    "    assert(L % 4 == 0), \"Frame length must be divisible by four.\"\n",
    "    Hs = L // 4\n",
    "\n",
    "    # determine interpolation points\n",
    "    target_dur = alignment[1,-1] # in sec\n",
    "    target_start_frm = int(np.ceil(alignment[1,0] * fs / Hs)) # if a subsequence alignment, output will be zero until target_start_frm\n",
    "    numFrames = int((target_dur * fs - L) // Hs) + 1\n",
    "    analysisFrames = np.zeros((numFrames, L))\n",
    "    interp_pts = np.interp(np.arange(numFrames)*Hs/fs, alignment[1,:], alignment[0,:]) # left edge of analysis windows\n",
    "\n",
    "    # compute analysis frames\n",
    "    for i in range(numFrames):\n",
    "        if i >= target_start_frm:\n",
    "            offset = int(np.round(interp_pts[i] * fs))\n",
    "            offset = min(offset, len(x) - L)\n",
    "            analysisFrames[i,:] = x[offset: offset + L]\n",
    "\n",
    "    # compute STFT\n",
    "    window = hann_window(L)\n",
    "    analysisFrames = analysisFrames * window.reshape((1,-1))\n",
    "    Xfull = np.fft.fft(analysisFrames, axis=1)\n",
    "    halfLen = L//2 + 1\n",
    "    X = Xfull[:,0:halfLen].T\n",
    "   \n",
    "    # compute modified STFT\n",
    "    w_if = estimateIF_var(X[:,target_start_frm:], fs, interp_pts[target_start_frm:]) # only for active frames\n",
    "    phase_mod = np.zeros(X.shape)\n",
    "    phase_mod[:,target_start_frm] = np.angle(X[:,target_start_frm])\n",
    "    for i in range(target_start_frm + 1, phase_mod.shape[1]):\n",
    "        phase_mod[:,i] = phase_mod[:,i-1] + w_if[:,i-target_start_frm-1] * Hs / fs\n",
    "    Xmod = np.abs(X) * np.exp(1j * phase_mod)\n",
    "    \n",
    "    # signal reconstruction\n",
    "    y = invert_stft(Xmod, Hs, window)\n",
    "    #y = lb.core.istft(Xmod, hop_length=Hs, center=False)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14845c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateIF_var(S, sr, timestamps):\n",
    "    '''\n",
    "    Estimates the instantaneous frequencies in an STFT-like matrix when the analysis frames\n",
    "    are not evenly spaced.\n",
    "    \n",
    "    Inputs\n",
    "    S: the STFT-like matrix, should only contain the lower half of the frequency bins\n",
    "    sr: sampling rate\n",
    "    timestamps: timestamps corresponding to each STFT column (in sec)\n",
    "    \n",
    "    Returns a matrix containing the estimated instantaneous frequency at each time-frequency bin.\n",
    "    This matrix should contain one less column than S.\n",
    "    '''\n",
    "    assert S.shape[1] == len(timestamps)\n",
    "#    hop_sec = hop_samples / sr\n",
    "    fft_size = (S.shape[0] - 1) * 2\n",
    "    w_nom = np.arange(S.shape[0]) * sr / fft_size * 2 * np.pi\n",
    "    w_nom = w_nom.reshape((-1,1))    \n",
    "    unwrapped = np.angle(S[:,1:]) - np.angle(S[:,0:-1]) - w_nom * (timestamps[1:] - timestamps[0:-1]).reshape((1,-1))\n",
    "    wrapped = (unwrapped + np.pi) % (2 * np.pi) - np.pi\n",
    "    w_if = w_nom + wrapped / (timestamps[1:] - timestamps[0:-1]).reshape((1,-1))\n",
    "    return w_if"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebe6f80c",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8088841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5061a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, sr = lb.load(lb.ex('nutcracker'))\n",
    "# y_mod = tsm_hybrid(y, alpha=0.8) # sped up\n",
    "# ipd.Audio(y_mod, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fded4674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment = np.zeros((2,20))\n",
    "# alignment[0,:] = np.arange(20)\n",
    "# alignment[1,:] = 25*(np.arange(20)/19)**0.6 # start slow & speed up\n",
    "# y_mod = tsmvar_hybrid(y, alignment)\n",
    "# ipd.Audio(y_mod, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bff0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
