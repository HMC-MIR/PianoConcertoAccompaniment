{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d952c15",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "652e61b6",
   "metadata": {},
   "source": [
    "This notebook runs a benchmark on a given system.  In order to run an experiment with a new system, you only need to do two things:\n",
    "- Implement the `offline_processing()` and `online_processing()` functions in a jupyter notebook for the new system.  You can use 02a_simpleOfflineDTW.ipynb as a template.\n",
    "- Import the notebook containing the system's implementation into this notebook as a python package.\n",
    "\n",
    "This notebook will run an entire benchmark using the specified system, and save the hypotheses to a specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a031a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import os.path\n",
    "import system_utils \n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "488e4e0e",
   "metadata": {},
   "source": [
    "The following cell should be modified to use the desired system of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3050b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from System_ISA.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdey/ttmp/micromamba/envs/PianoConcertoAccompaniment/lib/python3.9/site-packages/nbformat/__init__.py:92: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    }
   ],
   "source": [
    "import System_ISA as system  # replace this with new system\n",
    "\n",
    "# system parameters\n",
    "EXP_NAME = 'ISA_CHROMA' # experiment name, e.g. offlineDTW_train\n",
    "hop_size = 512\n",
    "sr = 22050\n",
    "dtw_steps = np.array([[1,1],[1,2],[2,1]])\n",
    "dtw_weights = np.array([1,1,2])\n",
    "use_multiprocessing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34ef76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change\n",
    "SCENARIOS_ROOT_DIR = 'scenarios'\n",
    "EXP_ROOT_DIR = f'experiments/{EXP_NAME}'\n",
    "CACHE_ROOT_DIR = f'{EXP_ROOT_DIR}/cache'\n",
    "SCENARIOS_SUMMARY = f'{SCENARIOS_ROOT_DIR}/scenarios.summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b299d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCacheDir(d, scenario_id):\n",
    "    '''\n",
    "    Returns the filepath of the cache directory for the given scenario id.  Note that the cache directory\n",
    "    can be shared as long as the orchestra and full mix files match, so its naming specifies information\n",
    "    from both.\n",
    "    \n",
    "    Inputs\n",
    "    d: dictionary summarizing the information in the scenarios.summary file\n",
    "    scenario_id: the identifier of the scenario of interest (e.g. s1)\n",
    "    '''\n",
    "    \n",
    "    o_id = os.path.splitext(os.path.basename(d[scenario_id]['o']))[0] # e.g. rach2_mov1_O1\n",
    "    po_id = os.path.splitext(os.path.basename(d[scenario_id]['po']))[0] # e.g. rach2_mov1_PO1\n",
    "    cache_id = o_id + '_' + po_id.split('_')[-1] # e.g. rach2_mov1_O1_PO1\n",
    "    cache_dir = f'{CACHE_ROOT_DIR}/{cache_id}' \n",
    "    \n",
    "    return cache_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcd120e8",
   "metadata": {},
   "source": [
    "The following function runs the offline processing stage.  You only need to edit the arguments to the `offline_processing()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eec5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runOfflineProcessing(cache = None):\n",
    "    '''\n",
    "    Runs the offline processing component (only) for every scenario using the specified system.\n",
    "    If the cache directory for the scenario already exists, the offline processing for that scenario\n",
    "    will be skipped.\n",
    "    \n",
    "    Inputs\n",
    "    cache: specify a cache directory to simply copy over, will bypass the offline processing stage\n",
    "    '''\n",
    "    \n",
    "    # setup\n",
    "    if not os.path.exists(EXP_ROOT_DIR):\n",
    "        os.makedirs(EXP_ROOT_DIR)\n",
    "    if cache is None:\n",
    "        if not os.path.exists(CACHE_ROOT_DIR): # create if not there, leave it alone if already present\n",
    "            os.mkdir(CACHE_ROOT_DIR)\n",
    "    else:\n",
    "        if os.path.exists(CACHE_ROOT_DIR): # replace with the specified cache directory\n",
    "            os.system(f'rm -rf {CACHE_ROOT_DIR}')\n",
    "        os.system(f'cp -r {cache} {CACHE_ROOT_DIR}')\n",
    "    \n",
    "    # run offline processing component for each scenario\n",
    "    d = system_utils.get_scenario_info(SCENARIOS_SUMMARY)    \n",
    "    for i in tqdm(range(len(d))):\n",
    "        scenario_id = f's{i+1}'\n",
    "        scenario_dir = f'{SCENARIOS_ROOT_DIR}/{scenario_id}'\n",
    "        cache_dir = getCacheDir(d, scenario_id)\n",
    "        if os.path.exists(cache_dir):\n",
    "            # print(f'Skipping offline processing for {scenario_id} -- cache already exists.')\n",
    "            system.verify_cache_dir(cache_dir) # optional: verify that cache directory has required files\n",
    "        else:\n",
    "            # print(f'Running offline processing for {scenario_id}')\n",
    "            # system.offline_processing(scenario_dir, cache_dir, hop_size, dtw_steps, dtw_weights) # offlineDTW and MATCH\n",
    "            # system.offline_processing(scenario_dir, cache_dir, hop_size, dtw_steps, dtw_weights, Path(cache_dir).parent, 'SPL-TTA') # separatedMatch\n",
    "            system.offline_processing(scenario_dir, cache_dir, hop_size, 'chroma') # ISA\n",
    "            # system.offline_processing(scenario_dir, cache_dir) # OfflineFlexDTW\n",
    "            # system.offline_processing(scenario_dir, cache_dir, hop_size) # NaivePairwiseDTW\n",
    "            # system.offline_processing(scenario_dir, cache_dir, hop_size, dtw_steps, dtw_weights, Path(cache_dir).parent, 'SPL-PT') # separatedDTW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56604c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71f169c14e24fc48d547f01f9641c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runOfflineProcessing()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "790adaaa",
   "metadata": {},
   "source": [
    "The following function runs the online processing stage.  You only need to edit the arguments to the `online_processing()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccd55f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleFileOnline(id, d, copydir):\n",
    "    copydir = None\n",
    "    scenario_id = f's{id+1}'\n",
    "    scenario_dir = f'{SCENARIOS_ROOT_DIR}/{scenario_id}'\n",
    "    out_dir = f'{EXP_ROOT_DIR}/{scenario_id}' # where to save hypothesis file\n",
    "    cache_dir = getCacheDir(d, scenario_id)\n",
    "    \n",
    "    if os.path.exists(out_dir):  # has already been processed -- skip\n",
    "        # print(f'Skipping online processing for {scenario_id} -- already processed')\n",
    "        system.verify_hyp_dir(out_dir)\n",
    "        return\n",
    "    \n",
    "    if copydir is not None: # copy over if already processed in copydir\n",
    "        src_dir = f'{copydir}/{scenario_id}' \n",
    "        if os.path.exists(src_dir):\n",
    "            # print(f'Skipping online processing for {scenario_id} -- copying from copydir')\n",
    "            os.system(f'cp -r {src_dir} {out_dir}')\n",
    "            return\n",
    "                \n",
    "    # print(f'Running online processing for {scenario_id}')\n",
    "    # system.online_processing(scenario_dir, out_dir, cache_dir, hop_size, dtw_steps, dtw_weights) # SimpleOfflineDTW\n",
    "    # system.online_processing(scenario_dir, out_dir, cache_dir, hop_size / sr, oracle=False) # MATCH\n",
    "    # system.online_processing(scenario_dir, out_dir, cache_dir, hop_size / sr, Path(cache_dir).parent, 'SPL-TTA', oracle=False) # separatedMATCH\n",
    "    system.online_processing(scenario_dir, out_dir, cache_dir, hop_size, 'chroma') # ISA\n",
    "    # system.online_processing(scenario_dir, out_dir, cache_dir) # OfflineFlexDTW\n",
    "    # system.online_processing(scenario_dir, out_dir, cache_dir, hop_size, dtw_steps, dtw_weights) # NaivePairwiseDTW\n",
    "    # system.online_processing(scenario_dir, out_dir, cache_dir, hop_size, dtw_steps, dtw_weights, Path(cache_dir).parent, 'SPL-PT') # separatedDTW\n",
    "    \n",
    "def runOnlineProcessing(copydir = None):\n",
    "    '''\n",
    "    Runs the online processing component for every scenario using the specified system.\n",
    "    If a copy directory is specified, the online processing results from the directory will be\n",
    "    copied over and skipped.\n",
    "    '''\n",
    "    \n",
    "    # verify\n",
    "    assert os.path.exists(EXP_ROOT_DIR)\n",
    "    assert os.path.exists(CACHE_ROOT_DIR)\n",
    "    d = system_utils.get_scenario_info(SCENARIOS_SUMMARY)    \n",
    "\n",
    "    if use_multiprocessing:\n",
    "        with Pool() as p:\n",
    "            p.starmap(singleFileOnline, [(id, d, copydir) for id in range(len(d))])\n",
    "    else:\n",
    "        for id in tqdm(range(len(d))):\n",
    "            singleFileOnline(id, d, copydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a92f80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fefb8a983441b6b9fe87515ad03419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdey/ttmp/micromamba/envs/PianoConcertoAccompaniment/lib/python3.9/site-packages/numba/core/ir_utils.py:2149: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'weights' of function 'dtw'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"../ttmp/micromamba/envs/PianoConcertoAccompaniment/lib/python3.9/site-packages/hmc_mir/align/dtw.py\", line 41:\u001b[0m\n",
      "\u001b[1m@jit(nopython=True)\n",
      "\u001b[1mdef dtw(C, steps, weights, subseq=False):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    }
   ],
   "source": [
    "runOnlineProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runOnlineProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cdc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
