{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d952c15",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e61b6",
   "metadata": {},
   "source": [
    "This notebook runs a benchmark on a given system.  In order to run an experiment with a new system, you only need to do two things:\n",
    "- Implement the `offline_processing()` and `online_processing()` functions in a jupyter notebook for the new system.  You can use 02a_simpleOfflineDTW.ipynb as a template.\n",
    "- Import the notebook containing the system's implementation into this notebook as a python package.\n",
    "\n",
    "This notebook will run an entire benchmark using the specified system, and save the hypotheses to a specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import System_MATCH as system # replace this with new system\n",
    "import numpy as np\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user specified\n",
    "EXP_NAME = 'match' # experiment name, e.g. simpleOfflineDTW_train\n",
    "SCENARIOS_ROOT_DIR = 'scenarios'\n",
    "hop_size = 512\n",
    "sr = 22050\n",
    "dtw_steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "dtw_weights = np.array([2,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change\n",
    "EXP_ROOT_DIR = f'experiments/{EXP_NAME}'\n",
    "CACHE_ROOT_DIR = f'{EXP_ROOT_DIR}/cache'\n",
    "SCENARIOS_SUMMARY = f'{SCENARIOS_ROOT_DIR}/scenarios.summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseScenariosSummary(infile):\n",
    "    '''\n",
    "    Parses the contents of the scenarios.summary file into a dictionary for easy lookup.\n",
    "    \n",
    "    Inputs\n",
    "    infile: The filepath to the scenarios.summary file\n",
    "    \n",
    "    Returns a nested dictionary whose key is the scenario id (e.g. s1, s2, etc).  The second (nested) key\n",
    "    is one of the following:\n",
    "      p: the piano filepath\n",
    "      o: the orchestra filepath\n",
    "      po: the full mix filepath\n",
    "      mStart: the index of the measure where the query starts (count starts from 1)\n",
    "      mEnd: the index of the measure where the query ends (inclusive)\n",
    "      pStart: the timestamp in the original full piano recording where the query begins (sec)\n",
    "      oStart: the ground truth timestamp in the orchestra recording corresponding to the beginning of the query (sec)\n",
    "    '''\n",
    "    d = {}\n",
    "    with open(infile, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            assert len(parts) == 10\n",
    "            scenario_id = parts[0]\n",
    "            d[scenario_id] = {}\n",
    "            d[scenario_id]['pfile'] = parts[1]\n",
    "            d[scenario_id]['ofile'] = parts[2]\n",
    "            d[scenario_id]['pofile'] = parts[3]\n",
    "            d[scenario_id]['mStart'] = int(parts[4])\n",
    "            d[scenario_id]['mEnd'] = int(parts[5])\n",
    "            d[scenario_id]['pStart'] = float(parts[6])\n",
    "            d[scenario_id]['pEnd'] = float(parts[7])\n",
    "            d[scenario_id]['oStart'] = float(parts[8])\n",
    "            d[scenario_id]['oEnd'] = float(parts[9])\n",
    "                \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCacheDir(d, scenario_id):\n",
    "    '''\n",
    "    Returns the filepath of the cache directory for the given scenario id.  Note that the cache directory\n",
    "    can be shared as long as the orchestra and full mix files match, so its naming specifies information\n",
    "    from both.\n",
    "    \n",
    "    Inputs\n",
    "    d: dictionary summarizing the information in the scenarios.summary file\n",
    "    scenario_id: the identifier of the scenario of interest (e.g. s1)\n",
    "    '''\n",
    "    \n",
    "    o_id = os.path.splitext(os.path.basename(d[scenario_id]['ofile']))[0] # e.g. rach2_mov1_O1\n",
    "    po_id = os.path.splitext(os.path.basename(d[scenario_id]['pofile']))[0] # e.g. rach2_mov1_PO1\n",
    "    cache_id = o_id + '_' + po_id.split('_')[-1] # e.g. rach2_mov1_O1_PO1\n",
    "    cache_dir = f'{CACHE_ROOT_DIR}/{cache_id}' \n",
    "    \n",
    "    return cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runOfflineProcessing(bypass = None):\n",
    "    '''\n",
    "    Runs the offline processing component (only) for every scenario using the specified system.\n",
    "    \n",
    "    Inputs\n",
    "    bypass: specify a directory to simply copy over, will bypass the offline processing stage\n",
    "    '''\n",
    "    \n",
    "    # bypass offline processing\n",
    "    if bypass is not None:\n",
    "        if not os.path.exists(EXP_ROOT_DIR):\n",
    "            os.makedirs(EXP_ROOT_DIR)\n",
    "        if not os.path.exists(CACHE_ROOT_DIR):\n",
    "            os.system(f'cp -r {bypass} {CACHE_ROOT_DIR}')\n",
    "        return\n",
    "    \n",
    "    # setup\n",
    "    assert not os.path.exists(EXP_ROOT_DIR)\n",
    "    os.makedirs(EXP_ROOT_DIR)\n",
    "    os.mkdir(CACHE_ROOT_DIR)\n",
    "    d = parseScenariosSummary(SCENARIOS_SUMMARY)\n",
    "    \n",
    "    # run offline processing component for each scenario\n",
    "    for i in range(len(d)):\n",
    "        \n",
    "        scenario_id = f's{i+1}'\n",
    "        scenario_dir = f'{SCENARIOS_ROOT_DIR}/{scenario_id}'\n",
    "        cache_dir = getCacheDir(d, scenario_id)        \n",
    "        print(f'Running offline processing for {scenario_id}')\n",
    "        system.offline_processing(scenario_dir, cache_dir, hop_size, dtw_steps, dtw_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56604c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runOfflineProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd55f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runOnlineProcessing():\n",
    "    '''\n",
    "    Runs the online processing component for every scenario using the specified system.\n",
    "    '''\n",
    "    \n",
    "    # verify\n",
    "    assert os.path.exists(EXP_ROOT_DIR)\n",
    "    assert os.path.exists(CACHE_ROOT_DIR)\n",
    "    d = parseScenariosSummary(SCENARIOS_SUMMARY)\n",
    "    \n",
    "    # run online processing component for each scenario\n",
    "    for i in range(len(d)):\n",
    "        \n",
    "        scenario_id = f's{i+1}'\n",
    "        scenario_dir = f'{SCENARIOS_ROOT_DIR}/{scenario_id}'\n",
    "        out_dir = f'{EXP_ROOT_DIR}/{scenario_id}' # where to save hypothesis file\n",
    "        cache_dir = getCacheDir(d, scenario_id)        \n",
    "        print(f'Running online processing for {scenario_id}')\n",
    "        system.online_processing(scenario_dir, out_dir, cache_dir, hop_size/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runOnlineProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15a24f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accompaniment",
   "language": "python",
   "name": "accompaniment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
