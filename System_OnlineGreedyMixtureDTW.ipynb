{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a79b99",
   "metadata": {},
   "source": [
    "# Online Greedy Mixture DTW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cb97f15",
   "metadata": {},
   "source": [
    "This notebook implements an online greedy mixture-based DTW approach.  The only requirement in this notebook is that it implement the `offline_processing()` and `online_processing()` functions, which will be imported and run in `02_RunExperiment.ipynb`.  The rest of the notebook is for experimenting, visualizing, and analyzing the system, so it should be thought of as a sandbox for development."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ff6b5de",
   "metadata": {},
   "source": [
    "Here is a summary of the online greedy mixture-based approach:\n",
    "- We assume that the piano part starts in the correct location of the orchestra recording\n",
    "- Chroma features are extracted from orchestra, piano, and full mix recordings\n",
    "- Without constructing a 3D cost tensor, we compute a mixture-based cost (dissimilarity between P+O and PO) on-the-fly and greedily select the next step\n",
    "\n",
    "Main findings:\n",
    "- We did not find any promising results from this approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d1df11",
   "metadata": {},
   "source": [
    "## Offline Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610e1142",
   "metadata": {},
   "source": [
    "In the offline processing stage, three things are computed and stored in the `cache/` folder:\n",
    "- chroma features for the orchestra recording\n",
    "- chroma features for the full mix recording\n",
    "- predicted DTW alignment between the orchestra and full mix recordings (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0653f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import os\n",
    "import os.path\n",
    "import system_utils\n",
    "import import_ipynb\n",
    "import align_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_processing(scenario_dir, cache_dir, hop_length, steps, weights):\n",
    "    '''\n",
    "    Carries out offline processing for a simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    cache_dir: The location of the cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "    \n",
    "    This function will store the computed chroma features and estimated alignment in the cache folder.\n",
    "    '''\n",
    "    \n",
    "    # setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    if os.path.exists(cache_dir):\n",
    "        # print(f'{cache_dir} has already been processed.  Skipping.')\n",
    "        pass\n",
    "    else:\n",
    "        # setup\n",
    "        os.makedirs(cache_dir)\n",
    "\n",
    "        # compute orchestra features\n",
    "        o_file = f'{scenario_dir}/o.wav'\n",
    "        y_o, sr = lb.core.load(o_file)\n",
    "        F_o = lb.feature.chroma_cqt(y=y_o, sr=sr, hop_length=hop_length, norm=2) \n",
    "\n",
    "        # compute full mix features\n",
    "        po_file = f'{scenario_dir}/po.wav'\n",
    "        y_po, sr = lb.core.load(po_file)\n",
    "        F_po = lb.feature.chroma_cqt(y=y_po, sr=sr, hop_length=hop_length, norm=2)\n",
    "      \n",
    "        # compute subsequence DTW alignment (orchestra as query) \n",
    "        orch_start_sec, orch_end_sec = system_utils.get_orchestra_start_end_times(scenario_dir)\n",
    "        orch_start_frm = int(np.round(orch_start_sec * sr / hop_length))\n",
    "        orch_end_frm = int(np.round(orch_end_sec * sr / hop_length)) + 1\n",
    "        wp = align_tools.compute_dtw_alignment(1 - F_o[:,orch_start_frm:orch_end_frm].T @ F_po, steps, weights, subseq = True)\n",
    "        wp[0,:] = wp[0,:] + orch_start_frm  # account for offset\n",
    "\n",
    "        # save to cache\n",
    "        np.save(f'{cache_dir}/o_chroma.npy', F_o)\n",
    "        np.save(f'{cache_dir}/po_chroma.npy', F_po)\n",
    "        np.save(f'{cache_dir}/o_po_align.npy', wp)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cache_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified cache directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/o_chroma.npy'), f'o_chroma.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/po_chroma.npy'), f'po_chroma.npy missing from {indir}'\n",
    "    assert os.path.exists(f'{indir}/o_po_align.npy'), f'o_po_align.npy missing from {indir}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "588ee8df",
   "metadata": {},
   "source": [
    "# Online Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cedd6f21",
   "metadata": {},
   "source": [
    "In the online processing stage, we do the following:\n",
    "- We define a set of allowable transitions in a 3D cost tensor, with axes corresponding to P, O, and PO frames\n",
    "- We do not actually allocate a 3D cost tensor.  Instead, we compute elements of this 3D tensor on-the-fly using a mixture-based cost and greedily select the next step to minimize cumulative cost.  The mixture-based cost indicates the dissimilarity between (a) the sum of piano and orchestra feature vectors, and (b) the full mix feature vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(part_cqt):\n",
    "    part_cqt_with_noise = part_cqt + np.abs(np.random.randn(*part_cqt.shape)) * 1e-8\n",
    "    part_cqt_norm = part_cqt_with_noise / np.linalg.norm(part_cqt_with_noise, axis=0)\n",
    "\n",
    "    mask = np.where(part_cqt_norm < np.max(part_cqt_norm) * 0.05)\n",
    "    part_cqt_norm[mask] = 0\n",
    "\n",
    "    return part_cqt_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_processing(scenario_dir, out_dir, cache_dir, hop_sec, steps, weights):\n",
    "    '''\n",
    "    Carries out `online' processing for a simple offline DTW system.\n",
    "    \n",
    "    Inputs\n",
    "    scenario_dir: The scenario directory to process\n",
    "    out_dir: The directory to put results, intermediate files, and logging info\n",
    "    cache_dir: The cache directory\n",
    "    hop_length: The hop length in samples used when computing chroma features\n",
    "    steps: an L x 2 array specifying the allowable DTW transitions\n",
    "    weights: a length L array specifying the DTW transition weights\n",
    "\n",
    "    This function will compute and save the predicted alignment in the output directory in a file hyp.npy\n",
    "    '''\n",
    "    \n",
    "    # verify & setup\n",
    "    system_utils.verify_scenario_dir(scenario_dir)\n",
    "    verify_cache_dir(cache_dir)\n",
    "    assert not os.path.exists(out_dir), f'Output directory {out_dir} already exists.'\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "    # compute features\n",
    "    p_file = f'{scenario_dir}/p.wav'\n",
    "    y, sr = lb.core.load(p_file)\n",
    "    F_p = lb.feature.chroma_cqt(y=y, sr=sr, hop_length=hop_length, norm=2)  # piano features\n",
    "    F_po = np.load(f'{cache_dir}/po_chroma.npy') # full mix features\n",
    "    F_o = np.load(f'{cache_dir}/o_chroma.npy') # orchestra features\n",
    "        \n",
    "    # determine the start time of the query in the orchestra recording (ground truth)\n",
    "    orch_start_sec, _ = system_utils.get_orchestra_query_boundaries(scenario_dir)\n",
    "    orch_start_frm = orch_start_sec / hop_sec  # keep max precision, don't round\n",
    "    \n",
    "    # infer the start time of the query in the full mix recording (estimated)\n",
    "    wp_BC_frm = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "    wp_BC_frm = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC_frm)) # prepend (0,0) to handle edge cases properly\n",
    "    wp_BC_sec = wp_BC_frm * hop_sec\n",
    "    fullmix_start_sec = np.interp(orch_start_sec, wp_BC_sec[1,:], wp_BC_sec[0,:])\n",
    "\n",
    "    F_o = F_o[:,int(orch_start_frm):]  # truncate orchestra features to start at query start\n",
    "    F_po = F_po[:,int(fullmix_start_sec/hop_sec):]  # truncate full mix features to start at query start\n",
    "\n",
    "    p_index = 0\n",
    "    po_index = 0\n",
    "    o_index = 0\n",
    "\n",
    "    path = []\n",
    "\n",
    "    steps = [\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 2],\n",
    "        [1, 2, 1],\n",
    "        [2, 1, 1],\n",
    "        [1, 2, 2],\n",
    "        [2, 1, 2],\n",
    "        [2, 2, 1],\n",
    "    ]\n",
    "\n",
    "    weights = [\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "    ]\n",
    "\n",
    "    while (p_index < F_p.shape[1]) and (po_index < F_po.shape[1]) and (o_index < F_o.shape[1]):\n",
    "        min_cost = np.inf\n",
    "        min_step = None\n",
    "\n",
    "        for step in steps:\n",
    "            p_index_new = p_index + step[0]\n",
    "            po_index_new = po_index + step[1]\n",
    "            o_index_new = o_index + step[2]\n",
    "\n",
    "            if (p_index_new >= F_p.shape[1]) or (po_index_new >= F_po.shape[1]) or (o_index_new >= F_o.shape[1]):\n",
    "                continue\n",
    "\n",
    "            cost = np.sum(weights[steps.index(step)] * (F_po[:, po_index_new] - (F_p[:, p_index_new] + F_o[:, o_index_new])))\n",
    "\n",
    "            if cost < min_cost:\n",
    "                min_cost = cost\n",
    "                min_step = step\n",
    "\n",
    "        if min_step is None:\n",
    "            break\n",
    "        \n",
    "        p_index += min_step[0]\n",
    "        po_index += min_step[1]\n",
    "        o_index += min_step[2]\n",
    "\n",
    "        path.append([p_index, po_index, o_index])\n",
    "\n",
    "    path = np.array(path)\n",
    "\n",
    "    wp_AC_sec = np.vstack((path[:,0], path[:,2])) * hop_sec\n",
    "    np.save(f'{out_dir}/hyp.npy', wp_AC_sec)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19710221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hyp_dir(indir):\n",
    "    '''\n",
    "    Verifies that the specified scenario hypothesis directory has the required files.\n",
    "    \n",
    "    Inputs\n",
    "    indir: The cache directory to verify\n",
    "    '''\n",
    "    assert os.path.exists(f'{indir}/hyp.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b28c8bb",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd9f6c3",
   "metadata": {},
   "source": [
    "Here is an example of how to call the offline and online processing functions on a scenario directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario_dir = 'scenarios/s2'\n",
    "# out_dir = 'experiments/test/s2'\n",
    "# cache_dir = 'experiments/test/cache'\n",
    "# hop_size = 512\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([2,3,3])\n",
    "# offline_processing(scenario_dir, cache_dir, hop_size, steps, weights)\n",
    "# online_processing(scenario_dir, out_dir, cache_dir, hop_size, steps, weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e13cef25",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffcc1aa6",
   "metadata": {},
   "source": [
    "Some code for debugging the system.  Can delete later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a631ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dir = 'scenarios/s2'\n",
    "out_dir = 'experiments/debug/s2'\n",
    "cache_dir = 'experiments/debug/cache'\n",
    "hop_length = 512\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "hop_sec = 512 / 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6320614",
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_processing(scenario_dir, cache_dir, hop_length, steps, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20dbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9538df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute features\n",
    "p_file = f'{scenario_dir}/p.wav'\n",
    "y, sr = lb.core.load(p_file)\n",
    "F_p = normalize_features(lb.feature.chroma_cqt(y=y, sr=sr, hop_length=hop_length, norm=2))  # piano features\n",
    "F_po = normalize_features(np.load(f'{cache_dir}/po_chroma.npy')) # full mix features\n",
    "F_o = normalize_features(np.load(f'{cache_dir}/o_chroma.npy')) # orchestra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbd15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the start time of the query in the orchestra recording (ground truth)\n",
    "orch_start_sec, _ = system_utils.get_orchestra_query_boundaries(scenario_dir)\n",
    "orch_start_frm = orch_start_sec / hop_sec  # keep max precision, don't round\n",
    "\n",
    "# infer the start time of the query in the full mix recording (estimated)\n",
    "wp_BC_frm = np.flipud(np.load(f'{cache_dir}/o_po_align.npy'))\n",
    "wp_BC_frm = np.hstack((np.array([0,0]).reshape((2,-1)), wp_BC_frm)) # prepend (0,0) to handle edge cases properly\n",
    "wp_BC_sec = wp_BC_frm * hop_sec\n",
    "fullmix_start_sec = np.interp(orch_start_sec, wp_BC_sec[1,:], wp_BC_sec[0,:])\n",
    "\n",
    "F_o = F_o[:,int(orch_start_frm):]  # truncate orchestra features to start at query start\n",
    "F_po = F_po[:,int(fullmix_start_sec/hop_sec):]  # truncate full mix features to start at query start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42966e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cost = np.zeros((F_p.shape[1], F_o.shape[1]))\n",
    "\n",
    "for i in range(F_p.shape[1]):\n",
    "    for j in range(F_o.shape[1]):\n",
    "        custom_cost[i,j] = np.dot(F_po[:, j], (F_p[:, i] + F_o[:, j])) / (np.linalg.norm(F_po[:, i]) + np.linalg.norm(F_p[:, i] + F_o[:, j]))\n",
    "\n",
    "custom_cost = 1-custom_cost/np.max(custom_cost)\n",
    "\n",
    "plt.imshow(custom_cost, origin = 'lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835293a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_index = 0\n",
    "o_index = 0\n",
    "\n",
    "path = []\n",
    "\n",
    "steps = [\n",
    "    [1, 1, 2],\n",
    "    [1, 2, 1],\n",
    "    [2, 1, 1],\n",
    "]\n",
    "\n",
    "while (p_index < F_p.shape[1]) and (o_index < F_o.shape[1]):\n",
    "    min_cost = np.inf\n",
    "    min_step = None\n",
    "\n",
    "    for step in steps:\n",
    "        p_index_new = p_index + step[0]\n",
    "        o_index_new = o_index + step[1]\n",
    "\n",
    "        if (p_index_new >= F_p.shape[1]) or (o_index_new >= F_o.shape[1]):\n",
    "            continue\n",
    "\n",
    "        cost = custom_cost[p_index_new, o_index_new] * step[2]\n",
    "\n",
    "        if cost < min_cost:\n",
    "            min_cost = cost\n",
    "            min_step = step\n",
    "\n",
    "    if min_step is None:\n",
    "        break\n",
    "\n",
    "    p_index += min_step[0]\n",
    "    o_index += min_step[1]\n",
    "\n",
    "    path.append([p_index, o_index])\n",
    "\n",
    "path = np.array(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(path[:,1], path[:,0], color='r')\n",
    "plt.imshow(custom_cost, origin = 'lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b744e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_AC_sec = path.T * hop_sec\n",
    "wp_AC_sec[1,:] += orch_start_sec\n",
    "np.save(f'{out_dir}/hyp.npy', wp_AC_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_index = 0\n",
    "po_index = 0\n",
    "o_index = 0\n",
    "\n",
    "path = []\n",
    "step_path = []\n",
    "\n",
    "steps = [\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 2, 1],\n",
    "    [1, 2, 1, 1],\n",
    "    [2, 1, 1, 1],\n",
    "    [1, 2, 2, 1],\n",
    "    [2, 1, 2, 1],\n",
    "    [2, 2, 1, 1],\n",
    "]\n",
    "\n",
    "while (p_index < F_p.shape[1]) and (po_index < F_po.shape[1]) and (o_index < F_o.shape[1]):\n",
    "    min_cost = np.inf\n",
    "    min_step = None\n",
    "\n",
    "    rand_steps = np.random.permutation(steps).tolist()\n",
    "\n",
    "    for step in rand_steps:\n",
    "        p_index_new = p_index + step[0]\n",
    "        po_index_new = po_index + step[1]\n",
    "        o_index_new = o_index + step[2]\n",
    "\n",
    "        if (p_index_new >= F_p.shape[1]) or (po_index_new >= F_po.shape[1]) or (o_index_new >= F_o.shape[1]):\n",
    "            continue\n",
    "\n",
    "        cost = step[3] * np.linalg.norm(F_po[:, po_index_new] - (F_p[:, p_index_new] + F_o[:, o_index_new]))\n",
    "\n",
    "        if cost < min_cost:\n",
    "            min_cost = cost\n",
    "            min_step = step\n",
    "\n",
    "    if min_step is None:\n",
    "        break\n",
    "    \n",
    "    p_index += min_step[0]\n",
    "    po_index += min_step[1]\n",
    "    o_index += min_step[2]\n",
    "\n",
    "    path.append([p_index, po_index, o_index])\n",
    "    step_path.append(steps.index(min_step))\n",
    "\n",
    "path = np.array(path)\n",
    "\n",
    "wp_AC_sec = np.vstack((path[:,0], path[:,2])) * hop_sec\n",
    "wp_AC_sec[1,:] += orch_start_sec\n",
    "np.save(f'{out_dir}/hyp.npy', wp_AC_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wp_AC_sec[0,:], wp_AC_sec[1,:])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc618589",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(step_path, bins=range(len(steps)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True, figsize=(15, 7))\n",
    "lb.display.specshow(F_o, y_axis='chroma', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='o')\n",
    "ax[0].label_outer()\n",
    "img = lb.display.specshow(F_p, y_axis='chroma', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='p')\n",
    "ax[1].label_outer()\n",
    "img = lb.display.specshow(F_po, y_axis='chroma', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='po')\n",
    "fig.colorbar(img, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688be2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PianoConcertoAccompaniment",
   "language": "python",
   "name": "pianoconcertoaccompaniment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
